{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The next generation of Infrastructure-as-Code: work with high-level constructs instead of getting lost in low-level cloud configuration. pltf is a higher-level Infrastructure-as-Code framework. Instead of hand-crafting low-level cloud config, you describe environments and services in concise YAML. pltf turns those high-level constructs into Terraform so you keep full portability\u2014generate the code, extend it, or take it with you. Why pltf Infrastructure-as-code is essential, but working directly with low-level cloud and Terraform can be complex. pltf bakes in cloud/IaC best practices so you can set up automated, scalable, and secure infrastructure quickly\u2014without being a full-time DevOps engineer. Because pltf emits Terraform, you avoid lock-in and can extend or own the generated code at any time. How It Works With pltf you write configuration files and run the CLI (locally or in CI/CD). The CLI connects to your cloud, renders Terraform (providers/backends/locals/remote state), and can execute Terraform for you. Status: active development, not yet production-hardened. Pin versions and review generated code before applying. There are two primary spec types: Environment : defines cloud/provider, account, region, backend, and shared modules (clusters, networks, IAM, ingress, etc.). You might have one per staging/prod/QA, or per engineer/PR for isolated sandboxes. Service : defines an application workload and the non-Kubernetes resources it needs, linked to an Environment. Service specs seamlessly connect to environment outputs and modules. Environment and service specs are linked via metadata.ref and envRef . What You Can Do Generate IaC fast : turn Environment/Service YAML into Terraform with consistent providers/backends/remote state. Mix modules : use the embedded catalog or your own ( source: custom ) with the same wiring rules. Choose backends : store state in s3|gcs|azurerm regardless of target cloud; use profiles for cross-account S3. Run Terraform safely : pltf terraform plan/apply/destroy/output/unlock auto-generate before executing TF. Validate & lint : structural checks plus suggestions (labels, unused vars). Preview : see provider/backend/labels/modules without running TF. Next Steps Follow Getting Started . Explore repo examples ( example/env.yaml , example/service.yaml ). Review Security . Quick Links Installation Getting Started Platform Usage CLI Reference Spec Guide Modules & Wiring Features References Security","title":"Home"},{"location":"#why-pltf","text":"Infrastructure-as-code is essential, but working directly with low-level cloud and Terraform can be complex. pltf bakes in cloud/IaC best practices so you can set up automated, scalable, and secure infrastructure quickly\u2014without being a full-time DevOps engineer. Because pltf emits Terraform, you avoid lock-in and can extend or own the generated code at any time.","title":"Why pltf"},{"location":"#how-it-works","text":"With pltf you write configuration files and run the CLI (locally or in CI/CD). The CLI connects to your cloud, renders Terraform (providers/backends/locals/remote state), and can execute Terraform for you. Status: active development, not yet production-hardened. Pin versions and review generated code before applying. There are two primary spec types: Environment : defines cloud/provider, account, region, backend, and shared modules (clusters, networks, IAM, ingress, etc.). You might have one per staging/prod/QA, or per engineer/PR for isolated sandboxes. Service : defines an application workload and the non-Kubernetes resources it needs, linked to an Environment. Service specs seamlessly connect to environment outputs and modules. Environment and service specs are linked via metadata.ref and envRef .","title":"How It Works"},{"location":"#what-you-can-do","text":"Generate IaC fast : turn Environment/Service YAML into Terraform with consistent providers/backends/remote state. Mix modules : use the embedded catalog or your own ( source: custom ) with the same wiring rules. Choose backends : store state in s3|gcs|azurerm regardless of target cloud; use profiles for cross-account S3. Run Terraform safely : pltf terraform plan/apply/destroy/output/unlock auto-generate before executing TF. Validate & lint : structural checks plus suggestions (labels, unused vars). Preview : see provider/backend/labels/modules without running TF.","title":"What You Can Do"},{"location":"#next-steps","text":"Follow Getting Started . Explore repo examples ( example/env.yaml , example/service.yaml ). Review Security .","title":"Next Steps"},{"location":"#quick-links","text":"Installation Getting Started Platform Usage CLI Reference Spec Guide Modules & Wiring Features References Security","title":"Quick Links"},{"location":"faq/","text":"Placeholder content. Replace with real Q&A. What is pltf? A CLI that turns YAML specs into Terraform. Can I use custom modules? Yes, set source: custom and provide a custom modules root. How do I pick a backend? Set backend.type to s3|gcs|azurerm regardless of provider.","title":"FAQ"},{"location":"features/","text":"Each major capability has its own page: Profiles & Defaults Validation & Lint Backends Custom Modules Placeholders & Wiring Secrets Variables Telemetry Secrets What: Manage app secrets without embedding them in specs/code. Secrets are stored as Kubernetes secrets and injected as env vars. Why: Avoid leaking credentials; keep rotation simple. Usage: Define secret keys in your spec under secrets and supply values via environment variables or CLI --var . Secrets are treated as TF variables, not locals. Notes: Services restart to pick up changes unless --no-restart is used. Bulk updates can consume .env -style inputs; values should come from env/CI secret stores, not hardcoded files. Terraform Generator What: Render Terraform from env/service specs without applying; handy for review, migration, or running TF directly. Why: Keep portability\u2014inspect/modify TF, hand to CI, or migrate away without lock-in. Commands: pltf generate for TF only; pltf terraform plan|apply|destroy|output|force-unlock to generate + run. Example (env): pltf generate -f env.yaml -e prod -o .pltf/env/prod # outputs providers.tf, backend.tf, modules/<...>, outputs.tf, versions.tf Example (service): pltf generate -f service.yaml -e prod -o .pltf/service/payments/prod Notes: Does not require cloud credentials to render. Backends are written per spec ( s3|gcs|azurerm ). Generated modules directory is self-contained for review or VCS. Variables What: Minimal templating to reuse specs across envs/services. Types: CLI --var , env-level variables , and placeholders. Placeholders: ${env_name} , ${layer_name} , ${module.<id>.<output>} , ${parent.<output>} , ${var.<name>} . Spec inputs: Declare variables in env specs or use --var key=value at runtime; service specs inherit envRef variables and can override via CLI. Example (env): variables : min_nodes : \"2\" max_nodes : \"5\" modules : - type : aws_eks min_nodes : \"${var.min_nodes}\" max_nodes : \"${var.max_nodes}\" pltf terraform apply -f env.yaml -e prod --var min_nodes = 3 --var max_nodes = 6 Parent outputs: In services, ${parent.<output>} references environment outputs (e.g., ${parent.domain} ).","title":"Overview"},{"location":"features/#secrets","text":"What: Manage app secrets without embedding them in specs/code. Secrets are stored as Kubernetes secrets and injected as env vars. Why: Avoid leaking credentials; keep rotation simple. Usage: Define secret keys in your spec under secrets and supply values via environment variables or CLI --var . Secrets are treated as TF variables, not locals. Notes: Services restart to pick up changes unless --no-restart is used. Bulk updates can consume .env -style inputs; values should come from env/CI secret stores, not hardcoded files.","title":"Secrets"},{"location":"features/#terraform-generator","text":"What: Render Terraform from env/service specs without applying; handy for review, migration, or running TF directly. Why: Keep portability\u2014inspect/modify TF, hand to CI, or migrate away without lock-in. Commands: pltf generate for TF only; pltf terraform plan|apply|destroy|output|force-unlock to generate + run. Example (env): pltf generate -f env.yaml -e prod -o .pltf/env/prod # outputs providers.tf, backend.tf, modules/<...>, outputs.tf, versions.tf Example (service): pltf generate -f service.yaml -e prod -o .pltf/service/payments/prod Notes: Does not require cloud credentials to render. Backends are written per spec ( s3|gcs|azurerm ). Generated modules directory is self-contained for review or VCS.","title":"Terraform Generator"},{"location":"features/#variables","text":"What: Minimal templating to reuse specs across envs/services. Types: CLI --var , env-level variables , and placeholders. Placeholders: ${env_name} , ${layer_name} , ${module.<id>.<output>} , ${parent.<output>} , ${var.<name>} . Spec inputs: Declare variables in env specs or use --var key=value at runtime; service specs inherit envRef variables and can override via CLI. Example (env): variables : min_nodes : \"2\" max_nodes : \"5\" modules : - type : aws_eks min_nodes : \"${var.min_nodes}\" max_nodes : \"${var.max_nodes}\" pltf terraform apply -f env.yaml -e prod --var min_nodes = 3 --var max_nodes = 6 Parent outputs: In services, ${parent.<output>} references environment outputs (e.g., ${parent.domain} ).","title":"Variables"},{"location":"installation/","text":"Homebrew (macOS/Linux) brew tap yindia/pltf brew install pltf If you previously tapped another repo, run brew untap <old> before tapping yindia/pltf . Install script (macOS/Linux/Windows via WSL or Git Bash) curl -sSL https://raw.githubusercontent.com/yindia/pltf/main/scripts/install.sh | sh Environment overrides: - REPO_OWNER / REPO_NAME to point at a fork - VERSION to pin a release tag (e.g. v1.2.3 ) - DEST to change install path (defaults to /usr/local/bin ) Docker docker build -t pltf . docker run --rm pltf --help From source go install ./... # or to build a local binary go build -o bin/pltf main.go Verify pltf --help pltf validate -f env.yaml Upgrade Homebrew: brew upgrade pltf Script: rerun the install script with the desired VERSION From source: git pull then rebuild","title":"Installation"},{"location":"installation/#homebrew-macoslinux","text":"brew tap yindia/pltf brew install pltf If you previously tapped another repo, run brew untap <old> before tapping yindia/pltf .","title":"Homebrew (macOS/Linux)"},{"location":"installation/#install-script-macoslinuxwindows-via-wsl-or-git-bash","text":"curl -sSL https://raw.githubusercontent.com/yindia/pltf/main/scripts/install.sh | sh Environment overrides: - REPO_OWNER / REPO_NAME to point at a fork - VERSION to pin a release tag (e.g. v1.2.3 ) - DEST to change install path (defaults to /usr/local/bin )","title":"Install script (macOS/Linux/Windows via WSL or Git Bash)"},{"location":"installation/#docker","text":"docker build -t pltf . docker run --rm pltf --help","title":"Docker"},{"location":"installation/#from-source","text":"go install ./... # or to build a local binary go build -o bin/pltf main.go","title":"From source"},{"location":"installation/#verify","text":"pltf --help pltf validate -f env.yaml","title":"Verify"},{"location":"installation/#upgrade","text":"Homebrew: brew upgrade pltf Script: rerun the install script with the desired VERSION From source: git pull then rebuild","title":"Upgrade"},{"location":"modules/","text":"Modules are discovered from a modules root where each module type directory contains a module.yaml . The CLI scans custom roots (when provided) and the embedded catalog. Modules marked source: custom must be found in your custom root; others fall back to embedded. Wiring rules Inputs auto-wire to outputs with the same name (current scope, or parent env for services). Required inputs without a value or matching output fail validation. Optional/default inputs can stay unwired if nothing matches. Templates ${module.*} , ${var.*} , ${parent.*} are supported and converted to Terraform traversals. Module metadata (module.yaml) Example fields: name : aws_eks type : aws_eks provider : aws version : 1.0.0 description : EKS cluster inputs : - name : cluster_name type : string required : true - name : enable_metrics type : bool required : true - name : env_name type : string required : true outputs : - name : k8s_cluster_name type : string Notes: - Inputs may include description , default , capability (optional). - Outputs may include description , capability . - Capabilities can declare provides / accepts to describe contracts. Embedded modules (AWS) aws_base , aws_dns , aws_eks , aws_k8s_base , aws_k8s_service , aws_nodegroup aws_postgres , aws_mysql , aws_redis , aws_dynamodb , aws_s3 , aws_ses , aws_sns , aws_sqs , aws_documentdb aws_iam_role , aws_iam_policy , aws_iam_user cloudfront_distribution GCP/Azure: no bundled modules yet; use custom modules or your own registry. You can target GCP/Azure providers with custom modules and backends. Custom modules Mark spec entries with source: custom to force lookup in your custom modules root ( --modules or profile modules_root ). Generate module.yaml for your module with pltf module init --path <module_dir> [--force] . Inventory commands: pltf module list|get [-m ./modules] -o table|json|yaml . Treat modules as black boxes: configure via inputs , consume declared outputs , and let wiring handle references. Module init helper Use pltf module init --path <module_dir> [--force] to generate or refresh module.yaml from an existing Terraform module. This inspects variables/outputs and writes a fresh descriptor (backing up or overwriting if --force ).","title":"Modules & Wiring"},{"location":"modules/#wiring-rules","text":"Inputs auto-wire to outputs with the same name (current scope, or parent env for services). Required inputs without a value or matching output fail validation. Optional/default inputs can stay unwired if nothing matches. Templates ${module.*} , ${var.*} , ${parent.*} are supported and converted to Terraform traversals.","title":"Wiring rules"},{"location":"modules/#module-metadata-moduleyaml","text":"Example fields: name : aws_eks type : aws_eks provider : aws version : 1.0.0 description : EKS cluster inputs : - name : cluster_name type : string required : true - name : enable_metrics type : bool required : true - name : env_name type : string required : true outputs : - name : k8s_cluster_name type : string Notes: - Inputs may include description , default , capability (optional). - Outputs may include description , capability . - Capabilities can declare provides / accepts to describe contracts.","title":"Module metadata (module.yaml)"},{"location":"modules/#embedded-modules-aws","text":"aws_base , aws_dns , aws_eks , aws_k8s_base , aws_k8s_service , aws_nodegroup aws_postgres , aws_mysql , aws_redis , aws_dynamodb , aws_s3 , aws_ses , aws_sns , aws_sqs , aws_documentdb aws_iam_role , aws_iam_policy , aws_iam_user cloudfront_distribution GCP/Azure: no bundled modules yet; use custom modules or your own registry. You can target GCP/Azure providers with custom modules and backends.","title":"Embedded modules (AWS)"},{"location":"modules/#custom-modules","text":"Mark spec entries with source: custom to force lookup in your custom modules root ( --modules or profile modules_root ). Generate module.yaml for your module with pltf module init --path <module_dir> [--force] . Inventory commands: pltf module list|get [-m ./modules] -o table|json|yaml . Treat modules as black boxes: configure via inputs , consume declared outputs , and let wiring handle references.","title":"Custom modules"},{"location":"modules/#module-init-helper","text":"Use pltf module init --path <module_dir> [--force] to generate or refresh module.yaml from an existing Terraform module. This inspects variables/outputs and writes a fresh descriptor (backing up or overwriting if --force ).","title":"Module init helper"},{"location":"platform/","text":"Use this page as a practical guide to the most common flows in pltf. Validate + Lint pltf validate -f env.yaml -e prod pltf validate -f service.yaml -e dev - Runs structural validation and lint suggestions (labels, unused vars). - Picks environment from --env , PLTF_DEFAULT_ENV , or profile default_env . Preview pltf preview -f env.yaml -e prod - Shows provider, backend type, labels, and modules without running Terraform. Generate (Terraform only) pltf generate -f env.yaml -e dev pltf generate -f service.yaml -e prod -m ./modules --out .pltf/service/prod pltf generate -f service.yaml -e dev --var cluster_name = my-dev - --modules/-m custom root; modules with source: custom resolve here first. - --out/-o defaults to .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/<env> . - --var/-v merges over env vars \u2192 service envRef vars \u2192 CLI vars. - File inputs pointing to existing files in the spec directory are copied into the output and paths are updated. Terraform commands pltf terraform plan -f service.yaml -e dev # supports --target, --parallelism, --detailed-exitcode, --plan-file pltf terraform apply -f env.yaml -e prod pltf terraform destroy -f env.yaml -e prod pltf terraform output -f service.yaml -e dev --json pltf terraform force-unlock -f env.yaml -e prod --lock-id = <id> - Automatically generates Terraform, ensures backend (S3/GCS/Azurerm). - Common flags: --target/-t , --parallelism/-p , --lock/-l , --lock-timeout/-T , --no-color/-C , --input/-i , --refresh/-r , --plan-file/-P , --detailed-exitcode/-d , --json/-j . Module inventory pltf module list [ -m ./modules ] [ -o table | json | yaml ] pltf module get aws_eks [ -m ./modules ] [ -o table | json | yaml ] pltf module init --path ./modules/aws_eks [ --force ] - Use source: custom in specs to force lookup from your custom root ( --modules or profile modules_root ); embedded modules remain available. Profiles & Defaults ~/.pltf/profile.yaml (or PLTF_PROFILE ) can set modules_root , default_env , default_out , telemetry . PLTF_DEFAULT_ENV is also respected for picking the environment. Backends backend.type can be s3|gcs|azurerm (independent of provider). backend.profile supports cross-account S3; optional region , container , resource_group .","title":"Platform"},{"location":"platform/#validate-lint","text":"pltf validate -f env.yaml -e prod pltf validate -f service.yaml -e dev - Runs structural validation and lint suggestions (labels, unused vars). - Picks environment from --env , PLTF_DEFAULT_ENV , or profile default_env .","title":"Validate + Lint"},{"location":"platform/#preview","text":"pltf preview -f env.yaml -e prod - Shows provider, backend type, labels, and modules without running Terraform.","title":"Preview"},{"location":"platform/#generate-terraform-only","text":"pltf generate -f env.yaml -e dev pltf generate -f service.yaml -e prod -m ./modules --out .pltf/service/prod pltf generate -f service.yaml -e dev --var cluster_name = my-dev - --modules/-m custom root; modules with source: custom resolve here first. - --out/-o defaults to .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/<env> . - --var/-v merges over env vars \u2192 service envRef vars \u2192 CLI vars. - File inputs pointing to existing files in the spec directory are copied into the output and paths are updated.","title":"Generate (Terraform only)"},{"location":"platform/#terraform-commands","text":"pltf terraform plan -f service.yaml -e dev # supports --target, --parallelism, --detailed-exitcode, --plan-file pltf terraform apply -f env.yaml -e prod pltf terraform destroy -f env.yaml -e prod pltf terraform output -f service.yaml -e dev --json pltf terraform force-unlock -f env.yaml -e prod --lock-id = <id> - Automatically generates Terraform, ensures backend (S3/GCS/Azurerm). - Common flags: --target/-t , --parallelism/-p , --lock/-l , --lock-timeout/-T , --no-color/-C , --input/-i , --refresh/-r , --plan-file/-P , --detailed-exitcode/-d , --json/-j .","title":"Terraform commands"},{"location":"platform/#module-inventory","text":"pltf module list [ -m ./modules ] [ -o table | json | yaml ] pltf module get aws_eks [ -m ./modules ] [ -o table | json | yaml ] pltf module init --path ./modules/aws_eks [ --force ] - Use source: custom in specs to force lookup from your custom root ( --modules or profile modules_root ); embedded modules remain available.","title":"Module inventory"},{"location":"platform/#profiles-defaults","text":"~/.pltf/profile.yaml (or PLTF_PROFILE ) can set modules_root , default_env , default_out , telemetry . PLTF_DEFAULT_ENV is also respected for picking the environment.","title":"Profiles &amp; Defaults"},{"location":"platform/#backends","text":"backend.type can be s3|gcs|azurerm (independent of provider). backend.profile supports cross-account S3; optional region , container , resource_group .","title":"Backends"},{"location":"specs/","text":"pltf reads YAML specs with kind: Environment or kind: Service . The CLI validates structure and wires modules based on names and templated references. Environment spec (kind: Environment) Minimal shape: apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : example-org provider : aws labels : team : platform backend : type : s3 bucket : example-tfstate # optional; auto-named if omitted region : us-east-1 environments : dev : account : \"111111111111\" region : us-east-1 variables : base_domain : dev.example.com secrets : db_password : {} modules : - id : base type : aws_base - id : dns type : aws_dns inputs : domain : var.base_domain Notes: - environments map holds per-env accounts/regions/vars/secrets. - modules list holds shared modules; id / type required; inputs optional; links supported. - Backend: backend.type can be s3|gcs|azurerm (independent of provider). backend.profile supports cross-account S3; container/resource_group for azurerm. - Modules can set source: custom to force resolution from your custom modules root ( --modules or profile modules_root ); others fall back to the embedded catalog. Service spec (kind: Service) Minimal shape: apiVersion : platform.io/v1 kind : Service metadata : name : payments-api ref : ./env.yaml # path to Environment spec envRef : dev : variables : cluster_name : dev-cluster modules : - id : app type : aws_k8s_service inputs : cluster_name : var.cluster_name public_uri : \"/payments\" image : \"ghcr.io/acme/payments:latest\" links : readwrite : - db - id : db type : aws_postgres Notes: - metadata.ref points to the Environment file (relative paths allowed). - envRef holds per-env variables/secrets merged after environment variables. - Modules can reference environment outputs via ${parent.<output>} . Variable precedence 1) Environment variables 2) Service envRef variables (service only) 3) CLI --var key=value Secrets vs locals Secrets remain as Terraform variables ( var.<name> ). Non-secrets become locals; var.<name> resolves to locals unless marked secret. Templated references ${module.<module>.<output>} \u2014 module output in current scope ${var.<name>} \u2014 logical variable; wires to locals/secrets when names match ${parent.<output>} \u2014 environment output via remote state (service only) ${env_name} / ${layer_name} \u2014 intrinsic placeholders; for services, layer_name is the service name","title":"Config"},{"location":"specs/#environment-spec-kind-environment","text":"Minimal shape: apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : example-org provider : aws labels : team : platform backend : type : s3 bucket : example-tfstate # optional; auto-named if omitted region : us-east-1 environments : dev : account : \"111111111111\" region : us-east-1 variables : base_domain : dev.example.com secrets : db_password : {} modules : - id : base type : aws_base - id : dns type : aws_dns inputs : domain : var.base_domain Notes: - environments map holds per-env accounts/regions/vars/secrets. - modules list holds shared modules; id / type required; inputs optional; links supported. - Backend: backend.type can be s3|gcs|azurerm (independent of provider). backend.profile supports cross-account S3; container/resource_group for azurerm. - Modules can set source: custom to force resolution from your custom modules root ( --modules or profile modules_root ); others fall back to the embedded catalog.","title":"Environment spec (kind: Environment)"},{"location":"specs/#service-spec-kind-service","text":"Minimal shape: apiVersion : platform.io/v1 kind : Service metadata : name : payments-api ref : ./env.yaml # path to Environment spec envRef : dev : variables : cluster_name : dev-cluster modules : - id : app type : aws_k8s_service inputs : cluster_name : var.cluster_name public_uri : \"/payments\" image : \"ghcr.io/acme/payments:latest\" links : readwrite : - db - id : db type : aws_postgres Notes: - metadata.ref points to the Environment file (relative paths allowed). - envRef holds per-env variables/secrets merged after environment variables. - Modules can reference environment outputs via ${parent.<output>} .","title":"Service spec (kind: Service)"},{"location":"specs/#variable-precedence","text":"1) Environment variables 2) Service envRef variables (service only) 3) CLI --var key=value","title":"Variable precedence"},{"location":"specs/#secrets-vs-locals","text":"Secrets remain as Terraform variables ( var.<name> ). Non-secrets become locals; var.<name> resolves to locals unless marked secret.","title":"Secrets vs locals"},{"location":"specs/#templated-references","text":"${module.<module>.<output>} \u2014 module output in current scope ${var.<name>} \u2014 logical variable; wires to locals/secrets when names match ${parent.<output>} \u2014 environment output via remote state (service only) ${env_name} / ${layer_name} \u2014 intrinsic placeholders; for services, layer_name is the service name","title":"Templated references"},{"location":"usage/","text":"pltf auto-detects whether a spec is an Environment or Service based on kind . Most commands accept --file/-f , --env/-e , --modules/-m , --out/-o , and --var/-v key=value . Profiles ( ~/.pltf/profile.yaml or PLTF_PROFILE ) can set defaults for modules_root and default_env . Command catalog pltf validate \u2014 validate + lint specs. pltf generate \u2014 render Terraform only. pltf preview \u2014 summarize provider/backend/labels/modules. pltf terraform plan|apply|destroy|output|force-unlock|graph \u2014 generate + run Terraform with standard TF flags. pltf module list|get|init \u2014 module inventory and metadata generation. pltf lint \u2014 lint only (also run implicitly by validate). validate What: Validate Environment or Service specs; auto-detects kind; runs lint suggestions (labels, unused vars). Flags: --file/-f \u2014 Path to the spec (default env.yaml ). --env/-e \u2014 Environment key (dev/prod/etc.). Example: pltf validate -f service.yaml -e dev generate What: Render Terraform only; no init/apply. Flags: --file/-f \u2014 Path to the spec. --env/-e \u2014 Environment key. --modules/-m \u2014 Custom modules root; source: custom resolves here first. --out/-o \u2014 Output dir (defaults to .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/<env> ). --var/-v \u2014 CLI var override key=value . Example: pltf generate -f service.yaml -e prod -m ./modules --out .pltf/service/prod preview What: Show provider, backend, labels, modules without running Terraform. Flags: --file/-f , --env/-e Example: pltf preview -f env.yaml -e prod terraform plan What: Generate + run terraform plan with standard flags. Plan flags: --target/-t \u2014 Target address (repeatable). --parallelism/-p \u2014 Max parallel operations. --lock/-l \u2014 Lock state (default true). --lock-timeout/-T \u2014 Lock timeout (e.g., 30s). --no-color/-C \u2014 Disable color output. --input/-i \u2014 Prompt for input (default false). --refresh/-r \u2014 Refresh state before plan (default true). --detailed-exitcode/-d \u2014 Enable TF detailed exit codes. --plan-file/-P \u2014 Write plan to a file. Shared flags: --file/-f , --env/-e , --modules/-m , --out/-o , --var/-v Example: pltf terraform plan -f service.yaml -e dev --detailed-exitcode --plan-file=/tmp/plan.tfplan terraform apply What: Generate + run terraform apply -auto-approve . Flags: Shared flags ( --file/-f , --env/-e , --modules/-m , --out/-o , --var/-v ). Example: pltf terraform apply -f env.yaml -e prod terraform destroy What: Generate (if needed) + run terraform destroy -auto-approve . Flags: Same as apply. Example: pltf terraform destroy -f env.yaml -e prod terraform output What: Show outputs (optionally JSON). Flags: --json/-j (JSON output), plus shared --file/-f , --env/-e , --modules/-m , --out/-o Example: pltf terraform output -f service.yaml -e dev --json terraform force-unlock What: Force unlock state. Flags: --lock-id (required), plus shared --file/-f , --env/-e , --modules/-m , --out/-o Example: pltf terraform force-unlock -f env.yaml -e prod --lock-id=12345 terraform graph What: Emit DOT graph. Default runs terraform graph ; --mode spec renders a dependency graph from the YAML only. Flags: --mode terraform|spec (default terraform), --plan-file/-P (passed to terraform graph), plus shared --file/-f , --env/-e , --modules/-m , --out/-o Example: pltf terraform graph -f env.yaml -e dev | dot -Tpng > graph.png module list What: List module inventory from embedded/custom roots. Flags: --modules/-m (modules root), --output/-o ( table|json|yaml ) Example: pltf module list -m ./modules -o json module get What: Show module details (inputs/outputs). Flags: Same as module list. Example: pltf module get aws_eks -m ./modules module init What: Generate module.yaml from an existing Terraform module dir. Flags: --path (module dir), --name , --type , --description , --out , --force (overwrite) Example: pltf module init --path ./modules/aws_eks --force Validate + Lint Structural validation plus lint suggestions (labels, unused vars). pltf validate -f env.yaml -e prod pltf validate -f service.yaml -e dev Generate Render Terraform without running it. File inputs that point to existing files (relative to the spec) are copied into the output directory and paths are updated. pltf generate -f env.yaml -e dev pltf generate -f service.yaml -e prod -o .pltf/service/prod pltf generate -f service.yaml -e dev -m ./custom-mods --var cluster_name = my-dev Flags: - --modules/-m custom modules root. Modules with source: custom are resolved only from the custom root; others fall back to embedded modules. - --out/-o output dir (defaults .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/<env> ). - --var/-v merges vars (env vars \u2192 service envRef vars \u2192 CLI vars). Terraform helpers Terraform commands live under pltf terraform ... and auto-generate before running TF. pltf terraform plan -f service.yaml -e dev # plan (supports --target, --parallelism, --detailed-exitcode, --plan-file) pltf terraform apply -f env.yaml -e prod # apply pltf terraform destroy -f env.yaml -e prod # destroy pltf terraform output -f service.yaml -e dev # outputs (--json supported) pltf terraform force-unlock -f env.yaml -e prod --lock-id = <id> Common flags: --target/-t , --parallelism/-p , --lock/-l , --lock-timeout/-T , --no-color/-C , --input/-i , --refresh/-r , --plan-file/-P , --detailed-exitcode/-d , --json/-j . Preview Quick summary (provider, backend, labels, modules) without TF. pltf preview -f env.yaml -e prod Module inventory pltf module list [ -m ./modules ] [ -o table | json | yaml ] pltf module get aws_eks [ -m ./modules ] [ -o table | json | yaml ] pltf module init --path ./modules/aws_eks [ --force ] Custom backends In env spec backend.type can be s3|gcs|azurerm regardless of provider. Optional region , container , resource_group , profile (S3) supported. Custom modules Mark a module with source: custom to force lookup in your custom modules root. Provide a custom root via --modules or profile modules_root ; embedded modules remain available for everything else. Generate module.yaml for your own TF module with pltf module init --path <module_dir> [--force] . Environment defaults PLTF_DEFAULT_ENV or profile default_env let you omit --env when only one environment applies. Completions pltf completion bash | zsh | fish | powershell","title":"Usage"},{"location":"usage/#command-catalog","text":"pltf validate \u2014 validate + lint specs. pltf generate \u2014 render Terraform only. pltf preview \u2014 summarize provider/backend/labels/modules. pltf terraform plan|apply|destroy|output|force-unlock|graph \u2014 generate + run Terraform with standard TF flags. pltf module list|get|init \u2014 module inventory and metadata generation. pltf lint \u2014 lint only (also run implicitly by validate).","title":"Command catalog"},{"location":"usage/#validate","text":"What: Validate Environment or Service specs; auto-detects kind; runs lint suggestions (labels, unused vars). Flags: --file/-f \u2014 Path to the spec (default env.yaml ). --env/-e \u2014 Environment key (dev/prod/etc.). Example: pltf validate -f service.yaml -e dev","title":"validate"},{"location":"usage/#generate","text":"What: Render Terraform only; no init/apply. Flags: --file/-f \u2014 Path to the spec. --env/-e \u2014 Environment key. --modules/-m \u2014 Custom modules root; source: custom resolves here first. --out/-o \u2014 Output dir (defaults to .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/<env> ). --var/-v \u2014 CLI var override key=value . Example: pltf generate -f service.yaml -e prod -m ./modules --out .pltf/service/prod","title":"generate"},{"location":"usage/#preview","text":"What: Show provider, backend, labels, modules without running Terraform. Flags: --file/-f , --env/-e Example: pltf preview -f env.yaml -e prod","title":"preview"},{"location":"usage/#terraform-plan","text":"What: Generate + run terraform plan with standard flags. Plan flags: --target/-t \u2014 Target address (repeatable). --parallelism/-p \u2014 Max parallel operations. --lock/-l \u2014 Lock state (default true). --lock-timeout/-T \u2014 Lock timeout (e.g., 30s). --no-color/-C \u2014 Disable color output. --input/-i \u2014 Prompt for input (default false). --refresh/-r \u2014 Refresh state before plan (default true). --detailed-exitcode/-d \u2014 Enable TF detailed exit codes. --plan-file/-P \u2014 Write plan to a file. Shared flags: --file/-f , --env/-e , --modules/-m , --out/-o , --var/-v Example: pltf terraform plan -f service.yaml -e dev --detailed-exitcode --plan-file=/tmp/plan.tfplan","title":"terraform plan"},{"location":"usage/#terraform-apply","text":"What: Generate + run terraform apply -auto-approve . Flags: Shared flags ( --file/-f , --env/-e , --modules/-m , --out/-o , --var/-v ). Example: pltf terraform apply -f env.yaml -e prod","title":"terraform apply"},{"location":"usage/#terraform-destroy","text":"What: Generate (if needed) + run terraform destroy -auto-approve . Flags: Same as apply. Example: pltf terraform destroy -f env.yaml -e prod","title":"terraform destroy"},{"location":"usage/#terraform-output","text":"What: Show outputs (optionally JSON). Flags: --json/-j (JSON output), plus shared --file/-f , --env/-e , --modules/-m , --out/-o Example: pltf terraform output -f service.yaml -e dev --json","title":"terraform output"},{"location":"usage/#terraform-force-unlock","text":"What: Force unlock state. Flags: --lock-id (required), plus shared --file/-f , --env/-e , --modules/-m , --out/-o Example: pltf terraform force-unlock -f env.yaml -e prod --lock-id=12345","title":"terraform force-unlock"},{"location":"usage/#terraform-graph","text":"What: Emit DOT graph. Default runs terraform graph ; --mode spec renders a dependency graph from the YAML only. Flags: --mode terraform|spec (default terraform), --plan-file/-P (passed to terraform graph), plus shared --file/-f , --env/-e , --modules/-m , --out/-o Example: pltf terraform graph -f env.yaml -e dev | dot -Tpng > graph.png","title":"terraform graph"},{"location":"usage/#module-list","text":"What: List module inventory from embedded/custom roots. Flags: --modules/-m (modules root), --output/-o ( table|json|yaml ) Example: pltf module list -m ./modules -o json","title":"module list"},{"location":"usage/#module-get","text":"What: Show module details (inputs/outputs). Flags: Same as module list. Example: pltf module get aws_eks -m ./modules","title":"module get"},{"location":"usage/#module-init","text":"What: Generate module.yaml from an existing Terraform module dir. Flags: --path (module dir), --name , --type , --description , --out , --force (overwrite) Example: pltf module init --path ./modules/aws_eks --force","title":"module init"},{"location":"usage/#validate-lint","text":"Structural validation plus lint suggestions (labels, unused vars). pltf validate -f env.yaml -e prod pltf validate -f service.yaml -e dev","title":"Validate + Lint"},{"location":"usage/#generate_1","text":"Render Terraform without running it. File inputs that point to existing files (relative to the spec) are copied into the output directory and paths are updated. pltf generate -f env.yaml -e dev pltf generate -f service.yaml -e prod -o .pltf/service/prod pltf generate -f service.yaml -e dev -m ./custom-mods --var cluster_name = my-dev Flags: - --modules/-m custom modules root. Modules with source: custom are resolved only from the custom root; others fall back to embedded modules. - --out/-o output dir (defaults .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/<env> ). - --var/-v merges vars (env vars \u2192 service envRef vars \u2192 CLI vars).","title":"Generate"},{"location":"usage/#terraform-helpers","text":"Terraform commands live under pltf terraform ... and auto-generate before running TF. pltf terraform plan -f service.yaml -e dev # plan (supports --target, --parallelism, --detailed-exitcode, --plan-file) pltf terraform apply -f env.yaml -e prod # apply pltf terraform destroy -f env.yaml -e prod # destroy pltf terraform output -f service.yaml -e dev # outputs (--json supported) pltf terraform force-unlock -f env.yaml -e prod --lock-id = <id> Common flags: --target/-t , --parallelism/-p , --lock/-l , --lock-timeout/-T , --no-color/-C , --input/-i , --refresh/-r , --plan-file/-P , --detailed-exitcode/-d , --json/-j .","title":"Terraform helpers"},{"location":"usage/#preview_1","text":"Quick summary (provider, backend, labels, modules) without TF. pltf preview -f env.yaml -e prod","title":"Preview"},{"location":"usage/#module-inventory","text":"pltf module list [ -m ./modules ] [ -o table | json | yaml ] pltf module get aws_eks [ -m ./modules ] [ -o table | json | yaml ] pltf module init --path ./modules/aws_eks [ --force ]","title":"Module inventory"},{"location":"usage/#custom-backends","text":"In env spec backend.type can be s3|gcs|azurerm regardless of provider. Optional region , container , resource_group , profile (S3) supported.","title":"Custom backends"},{"location":"usage/#custom-modules","text":"Mark a module with source: custom to force lookup in your custom modules root. Provide a custom root via --modules or profile modules_root ; embedded modules remain available for everything else. Generate module.yaml for your own TF module with pltf module init --path <module_dir> [--force] .","title":"Custom modules"},{"location":"usage/#environment-defaults","text":"PLTF_DEFAULT_ENV or profile default_env let you omit --env when only one environment applies.","title":"Environment defaults"},{"location":"usage/#completions","text":"pltf completion bash | zsh | fish | powershell","title":"Completions"},{"location":"cli/pltf/","text":"pltf Platform toolkit for validating and generating Terraform stacks Synopsis pltf consumes YAML definitions for platform \"environments\" and application \"services\" and produces validated Terraform. Environment files capture accounts, regions, shared modules, and defaults; Service files reference an environment and declare app-specific modules. pltf checks structure and wiring, then renders Terraform with remote state, providers, locals, secrets, and module connections. Modules are discovered from a modules root where each module type exposes a module.yaml (generated via pltf module init). pltf [flags] Examples # Validate configs pltf env validate --file env.yaml pltf service validate --file service.yaml # Generate Terraform for dev pltf env generate --file env.yaml --env dev pltf service generate --file service.yaml --env dev # Scaffold module metadata for an existing TF module pltf module init --path ./modules/aws_eks Options -h, --help help for pltf --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf completion - Generate the autocompletion script for the specified shell pltf generate - Generate Terraform from an Environment or Service spec (auto-detects kind) pltf lint - Lint an Environment or Service spec and suggest fixes pltf module - Helpers for working with Terraform modules pltf preview - Preview a spec: provider, backend, modules, labels (no Terraform run) pltf terraform - Terraform helpers (generate+init+tf commands) pltf validate - Validate an Environment or Service spec (auto-detects kind) Auto generated by spf13/cobra on 20-Dec-2025","title":"pltf"},{"location":"cli/pltf/#pltf","text":"Platform toolkit for validating and generating Terraform stacks","title":"pltf"},{"location":"cli/pltf/#synopsis","text":"pltf consumes YAML definitions for platform \"environments\" and application \"services\" and produces validated Terraform. Environment files capture accounts, regions, shared modules, and defaults; Service files reference an environment and declare app-specific modules. pltf checks structure and wiring, then renders Terraform with remote state, providers, locals, secrets, and module connections. Modules are discovered from a modules root where each module type exposes a module.yaml (generated via pltf module init). pltf [flags]","title":"Synopsis"},{"location":"cli/pltf/#examples","text":"# Validate configs pltf env validate --file env.yaml pltf service validate --file service.yaml # Generate Terraform for dev pltf env generate --file env.yaml --env dev pltf service generate --file service.yaml --env dev # Scaffold module metadata for an existing TF module pltf module init --path ./modules/aws_eks","title":"Examples"},{"location":"cli/pltf/#options","text":"-h, --help help for pltf --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options"},{"location":"cli/pltf/#see-also","text":"pltf completion - Generate the autocompletion script for the specified shell pltf generate - Generate Terraform from an Environment or Service spec (auto-detects kind) pltf lint - Lint an Environment or Service spec and suggest fixes pltf module - Helpers for working with Terraform modules pltf preview - Preview a spec: provider, backend, modules, labels (no Terraform run) pltf terraform - Terraform helpers (generate+init+tf commands) pltf validate - Validate an Environment or Service spec (auto-detects kind)","title":"SEE ALSO"},{"location":"cli/pltf/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_completion/","text":"pltf completion Generate the autocompletion script for the specified shell Synopsis Generate the autocompletion script for pltf for the specified shell. See each sub-command's help for details on how to use the generated script. Options -h, --help help for completion Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks pltf completion bash - Generate the autocompletion script for bash pltf completion fish - Generate the autocompletion script for fish pltf completion powershell - Generate the autocompletion script for powershell pltf completion zsh - Generate the autocompletion script for zsh Auto generated by spf13/cobra on 20-Dec-2025","title":"Pltf completion"},{"location":"cli/pltf_completion/#pltf-completion","text":"Generate the autocompletion script for the specified shell","title":"pltf completion"},{"location":"cli/pltf_completion/#synopsis","text":"Generate the autocompletion script for pltf for the specified shell. See each sub-command's help for details on how to use the generated script.","title":"Synopsis"},{"location":"cli/pltf_completion/#options","text":"-h, --help help for completion","title":"Options"},{"location":"cli/pltf_completion/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_completion/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks pltf completion bash - Generate the autocompletion script for bash pltf completion fish - Generate the autocompletion script for fish pltf completion powershell - Generate the autocompletion script for powershell pltf completion zsh - Generate the autocompletion script for zsh","title":"SEE ALSO"},{"location":"cli/pltf_completion/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_completion_bash/","text":"pltf completion bash Generate the autocompletion script for bash Synopsis Generate the autocompletion script for the bash shell. This script depends on the 'bash-completion' package. If it is not installed already, you can install it via your OS's package manager. To load completions in your current shell session: source <(pltf completion bash) To load completions for every new session, execute once: Linux: pltf completion bash > /etc/bash_completion.d/pltf macOS: pltf completion bash > $(brew --prefix)/etc/bash_completion.d/pltf You will need to start a new shell for this setup to take effect. pltf completion bash Options -h, --help help for bash --no-descriptions disable completion descriptions Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf completion - Generate the autocompletion script for the specified shell Auto generated by spf13/cobra on 20-Dec-2025","title":"Pltf completion bash"},{"location":"cli/pltf_completion_bash/#pltf-completion-bash","text":"Generate the autocompletion script for bash","title":"pltf completion bash"},{"location":"cli/pltf_completion_bash/#synopsis","text":"Generate the autocompletion script for the bash shell. This script depends on the 'bash-completion' package. If it is not installed already, you can install it via your OS's package manager. To load completions in your current shell session: source <(pltf completion bash) To load completions for every new session, execute once:","title":"Synopsis"},{"location":"cli/pltf_completion_bash/#linux","text":"pltf completion bash > /etc/bash_completion.d/pltf","title":"Linux:"},{"location":"cli/pltf_completion_bash/#macos","text":"pltf completion bash > $(brew --prefix)/etc/bash_completion.d/pltf You will need to start a new shell for this setup to take effect. pltf completion bash","title":"macOS:"},{"location":"cli/pltf_completion_bash/#options","text":"-h, --help help for bash --no-descriptions disable completion descriptions","title":"Options"},{"location":"cli/pltf_completion_bash/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_completion_bash/#see-also","text":"pltf completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"cli/pltf_completion_bash/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_completion_fish/","text":"pltf completion fish Generate the autocompletion script for fish Synopsis Generate the autocompletion script for the fish shell. To load completions in your current shell session: pltf completion fish | source To load completions for every new session, execute once: pltf completion fish > ~/.config/fish/completions/pltf.fish You will need to start a new shell for this setup to take effect. pltf completion fish [flags] Options -h, --help help for fish --no-descriptions disable completion descriptions Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf completion - Generate the autocompletion script for the specified shell Auto generated by spf13/cobra on 20-Dec-2025","title":"Pltf completion fish"},{"location":"cli/pltf_completion_fish/#pltf-completion-fish","text":"Generate the autocompletion script for fish","title":"pltf completion fish"},{"location":"cli/pltf_completion_fish/#synopsis","text":"Generate the autocompletion script for the fish shell. To load completions in your current shell session: pltf completion fish | source To load completions for every new session, execute once: pltf completion fish > ~/.config/fish/completions/pltf.fish You will need to start a new shell for this setup to take effect. pltf completion fish [flags]","title":"Synopsis"},{"location":"cli/pltf_completion_fish/#options","text":"-h, --help help for fish --no-descriptions disable completion descriptions","title":"Options"},{"location":"cli/pltf_completion_fish/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_completion_fish/#see-also","text":"pltf completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"cli/pltf_completion_fish/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_completion_powershell/","text":"pltf completion powershell Generate the autocompletion script for powershell Synopsis Generate the autocompletion script for powershell. To load completions in your current shell session: pltf completion powershell | Out-String | Invoke-Expression To load completions for every new session, add the output of the above command to your powershell profile. pltf completion powershell [flags] Options -h, --help help for powershell --no-descriptions disable completion descriptions Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf completion - Generate the autocompletion script for the specified shell Auto generated by spf13/cobra on 20-Dec-2025","title":"Pltf completion powershell"},{"location":"cli/pltf_completion_powershell/#pltf-completion-powershell","text":"Generate the autocompletion script for powershell","title":"pltf completion powershell"},{"location":"cli/pltf_completion_powershell/#synopsis","text":"Generate the autocompletion script for powershell. To load completions in your current shell session: pltf completion powershell | Out-String | Invoke-Expression To load completions for every new session, add the output of the above command to your powershell profile. pltf completion powershell [flags]","title":"Synopsis"},{"location":"cli/pltf_completion_powershell/#options","text":"-h, --help help for powershell --no-descriptions disable completion descriptions","title":"Options"},{"location":"cli/pltf_completion_powershell/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_completion_powershell/#see-also","text":"pltf completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"cli/pltf_completion_powershell/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_completion_zsh/","text":"pltf completion zsh Generate the autocompletion script for zsh Synopsis Generate the autocompletion script for the zsh shell. If shell completion is not already enabled in your environment you will need to enable it. You can execute the following once: echo \"autoload -U compinit; compinit\" >> ~/. zshrc To load completions in your current shell session: source <(pltf completion zsh) To load completions for every new session, execute once: Linux: pltf completion zsh > \" ${ fpath [ 1 ] } /_pltf\" macOS: pltf completion zsh > $(brew --prefix)/share/zsh/site-functions/_pltf You will need to start a new shell for this setup to take effect. pltf completion zsh [flags] Options -h, --help help for zsh --no-descriptions disable completion descriptions Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf completion - Generate the autocompletion script for the specified shell Auto generated by spf13/cobra on 20-Dec-2025","title":"Pltf completion zsh"},{"location":"cli/pltf_completion_zsh/#pltf-completion-zsh","text":"Generate the autocompletion script for zsh","title":"pltf completion zsh"},{"location":"cli/pltf_completion_zsh/#synopsis","text":"Generate the autocompletion script for the zsh shell. If shell completion is not already enabled in your environment you will need to enable it. You can execute the following once: echo \"autoload -U compinit; compinit\" >> ~/. zshrc To load completions in your current shell session: source <(pltf completion zsh) To load completions for every new session, execute once:","title":"Synopsis"},{"location":"cli/pltf_completion_zsh/#linux","text":"pltf completion zsh > \" ${ fpath [ 1 ] } /_pltf\"","title":"Linux:"},{"location":"cli/pltf_completion_zsh/#macos","text":"pltf completion zsh > $(brew --prefix)/share/zsh/site-functions/_pltf You will need to start a new shell for this setup to take effect. pltf completion zsh [flags]","title":"macOS:"},{"location":"cli/pltf_completion_zsh/#options","text":"-h, --help help for zsh --no-descriptions disable completion descriptions","title":"Options"},{"location":"cli/pltf_completion_zsh/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_completion_zsh/#see-also","text":"pltf completion - Generate the autocompletion script for the specified shell","title":"SEE ALSO"},{"location":"cli/pltf_completion_zsh/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_generate/","text":"pltf generate Generate Terraform from an Environment or Service spec (auto-detects kind) Synopsis Read a YAML spec, detect Environment vs Service, and render Terraform with the proper remote state, providers, locals, secrets, and module wiring. Uses embedded modules by default; can override modules root and output directory. pltf generate [flags] Examples pltf generate -f env.yaml -e dev pltf generate -f service.yaml -e prod -m ./modules -o .pltf/my-env/my-svc/env/prod Options -e, --env string Environment key to render (dev, prod, etc.); required for both env and service specs -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for generate -m, --modules string Root directory containing module type folders with module.yaml metadata; defaults to embedded modules bundle -o, --out string Output directory for generated Terraform (defaults based on kind: .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/env/<env>) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides. Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks Auto generated by spf13/cobra on 20-Dec-2025","title":"generate"},{"location":"cli/pltf_generate/#pltf-generate","text":"Generate Terraform from an Environment or Service spec (auto-detects kind)","title":"pltf generate"},{"location":"cli/pltf_generate/#synopsis","text":"Read a YAML spec, detect Environment vs Service, and render Terraform with the proper remote state, providers, locals, secrets, and module wiring. Uses embedded modules by default; can override modules root and output directory. pltf generate [flags]","title":"Synopsis"},{"location":"cli/pltf_generate/#examples","text":"pltf generate -f env.yaml -e dev pltf generate -f service.yaml -e prod -m ./modules -o .pltf/my-env/my-svc/env/prod","title":"Examples"},{"location":"cli/pltf_generate/#options","text":"-e, --env string Environment key to render (dev, prod, etc.); required for both env and service specs -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for generate -m, --modules string Root directory containing module type folders with module.yaml metadata; defaults to embedded modules bundle -o, --out string Output directory for generated Terraform (defaults based on kind: .pltf/<env_name>/env/<env> or .pltf/<env_name>/<service>/env/<env>) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides.","title":"Options"},{"location":"cli/pltf_generate/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_generate/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks","title":"SEE ALSO"},{"location":"cli/pltf_generate/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_lint/","text":"pltf lint Lint an Environment or Service spec and suggest fixes Synopsis Perform structural validation plus lightweight linting (unused variables, missing labels) for Environment or Service specs. pltf lint [flags] Options -e, --env string Environment key to lint (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for lint Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks Auto generated by spf13/cobra on 20-Dec-2025","title":"lint"},{"location":"cli/pltf_lint/#pltf-lint","text":"Lint an Environment or Service spec and suggest fixes","title":"pltf lint"},{"location":"cli/pltf_lint/#synopsis","text":"Perform structural validation plus lightweight linting (unused variables, missing labels) for Environment or Service specs. pltf lint [flags]","title":"Synopsis"},{"location":"cli/pltf_lint/#options","text":"-e, --env string Environment key to lint (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for lint","title":"Options"},{"location":"cli/pltf_lint/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_lint/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks","title":"SEE ALSO"},{"location":"cli/pltf_lint/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_module/","text":"pltf module Helpers for working with Terraform modules Synopsis Inspect Terraform modules and scaffold module.yaml metadata files used by env/service generation and module discovery. Options -h, --help help for module Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks pltf module get - Show details for a module (inputs/outputs) pltf module init - Generate a module.yaml from an existing Terraform module pltf module list - List available modules (reads module.yaml inventory) Auto generated by spf13/cobra on 20-Dec-2025","title":"Overview"},{"location":"cli/pltf_module/#pltf-module","text":"Helpers for working with Terraform modules","title":"pltf module"},{"location":"cli/pltf_module/#synopsis","text":"Inspect Terraform modules and scaffold module.yaml metadata files used by env/service generation and module discovery.","title":"Synopsis"},{"location":"cli/pltf_module/#options","text":"-h, --help help for module","title":"Options"},{"location":"cli/pltf_module/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_module/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks pltf module get - Show details for a module (inputs/outputs) pltf module init - Generate a module.yaml from an existing Terraform module pltf module list - List available modules (reads module.yaml inventory)","title":"SEE ALSO"},{"location":"cli/pltf_module/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_module_get/","text":"pltf module get Show details for a module (inputs/outputs) Synopsis Display module metadata from module.yaml including provider, version, inputs, and outputs. pltf module get <module_type> [flags] Options -h, --help help for get -m, --modules string Modules root; defaults to embedded modules -o, --output string Output format: table|json|yaml (default \"table\") Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf module - Helpers for working with Terraform modules Auto generated by spf13/cobra on 20-Dec-2025","title":"get"},{"location":"cli/pltf_module_get/#pltf-module-get","text":"Show details for a module (inputs/outputs)","title":"pltf module get"},{"location":"cli/pltf_module_get/#synopsis","text":"Display module metadata from module.yaml including provider, version, inputs, and outputs. pltf module get <module_type> [flags]","title":"Synopsis"},{"location":"cli/pltf_module_get/#options","text":"-h, --help help for get -m, --modules string Modules root; defaults to embedded modules -o, --output string Output format: table|json|yaml (default \"table\")","title":"Options"},{"location":"cli/pltf_module_get/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_module_get/#see-also","text":"pltf module - Helpers for working with Terraform modules","title":"SEE ALSO"},{"location":"cli/pltf_module_get/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_module_init/","text":"pltf module init Generate a module.yaml from an existing Terraform module Synopsis Scan a Terraform module directory, read variables/outputs, and write a module.yaml descriptor. If module.yaml already exists at the destination it will be replaced. Use flags to override metadata such as name, type, description, or output path. Provider defaults to aws and version to 1.0.0. pltf module init [flags] Examples # Generate module.yaml inside ./modules/aws_eks pltf module init --path ./modules/aws_eks # Write to a custom location and override name/type pltf module init --path ./modules/db --name postgres --type aws_postgres --out ./modules/db/module.yaml Options --description string Human-readable description for the module; optional --force Overwrite an existing module.yaml (backs up to module.yaml.bak-<timestamp> when absent) -h, --help help for init --name string Module name to write into module.yaml (defaults to directory name) --out string Output path for module.yaml (defaults to <path>/module.yaml) --path string Directory containing the Terraform module to inspect; defaults to current directory (default \".\") --type string Logical module type; defaults to the module name when omitted Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf module - Helpers for working with Terraform modules Auto generated by spf13/cobra on 20-Dec-2025","title":"init"},{"location":"cli/pltf_module_init/#pltf-module-init","text":"Generate a module.yaml from an existing Terraform module","title":"pltf module init"},{"location":"cli/pltf_module_init/#synopsis","text":"Scan a Terraform module directory, read variables/outputs, and write a module.yaml descriptor. If module.yaml already exists at the destination it will be replaced. Use flags to override metadata such as name, type, description, or output path. Provider defaults to aws and version to 1.0.0. pltf module init [flags]","title":"Synopsis"},{"location":"cli/pltf_module_init/#examples","text":"# Generate module.yaml inside ./modules/aws_eks pltf module init --path ./modules/aws_eks # Write to a custom location and override name/type pltf module init --path ./modules/db --name postgres --type aws_postgres --out ./modules/db/module.yaml","title":"Examples"},{"location":"cli/pltf_module_init/#options","text":"--description string Human-readable description for the module; optional --force Overwrite an existing module.yaml (backs up to module.yaml.bak-<timestamp> when absent) -h, --help help for init --name string Module name to write into module.yaml (defaults to directory name) --out string Output path for module.yaml (defaults to <path>/module.yaml) --path string Directory containing the Terraform module to inspect; defaults to current directory (default \".\") --type string Logical module type; defaults to the module name when omitted","title":"Options"},{"location":"cli/pltf_module_init/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_module_init/#see-also","text":"pltf module - Helpers for working with Terraform modules","title":"SEE ALSO"},{"location":"cli/pltf_module_init/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_module_list/","text":"pltf module list List available modules (reads module.yaml inventory) Synopsis Scan a modules root for module.yaml files and list the module types, providers, and descriptions. pltf module list [flags] Options -h, --help help for list -m, --modules string Modules root; defaults to embedded modules -o, --output string Output format: table|json|yaml (default \"table\") Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf module - Helpers for working with Terraform modules Auto generated by spf13/cobra on 20-Dec-2025","title":"list"},{"location":"cli/pltf_module_list/#pltf-module-list","text":"List available modules (reads module.yaml inventory)","title":"pltf module list"},{"location":"cli/pltf_module_list/#synopsis","text":"Scan a modules root for module.yaml files and list the module types, providers, and descriptions. pltf module list [flags]","title":"Synopsis"},{"location":"cli/pltf_module_list/#options","text":"-h, --help help for list -m, --modules string Modules root; defaults to embedded modules -o, --output string Output format: table|json|yaml (default \"table\")","title":"Options"},{"location":"cli/pltf_module_list/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_module_list/#see-also","text":"pltf module - Helpers for working with Terraform modules","title":"SEE ALSO"},{"location":"cli/pltf_module_list/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_preview/","text":"pltf preview Preview a spec: provider, backend, modules, labels (no Terraform run) Synopsis Parse a spec (Environment or Service) and show a concise summary: provider, backend type, environment, labels, and modules to be rendered. pltf preview [flags] Options -e, --env string Environment key to use for preview -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for preview Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks Auto generated by spf13/cobra on 20-Dec-2025","title":"preview"},{"location":"cli/pltf_preview/#pltf-preview","text":"Preview a spec: provider, backend, modules, labels (no Terraform run)","title":"pltf preview"},{"location":"cli/pltf_preview/#synopsis","text":"Parse a spec (Environment or Service) and show a concise summary: provider, backend type, environment, labels, and modules to be rendered. pltf preview [flags]","title":"Synopsis"},{"location":"cli/pltf_preview/#options","text":"-e, --env string Environment key to use for preview -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for preview","title":"Options"},{"location":"cli/pltf_preview/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_preview/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks","title":"SEE ALSO"},{"location":"cli/pltf_preview/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform/","text":"pltf terraform Terraform helpers (generate+init+tf commands) Options -h, --help help for terraform Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks pltf terraform apply - Generate and apply Terraform for a spec pltf terraform destroy - Generate (if needed) and destroy Terraform for a spec pltf terraform force-unlock - Force unlock Terraform state for a spec pltf terraform graph - Generate a DOT graph for a spec (terraform graph or spec dependency graph) pltf terraform output - Show terraform outputs for a generated spec pltf terraform plan - Generate (if needed) and run terraform plan for a spec Auto generated by spf13/cobra on 20-Dec-2025","title":"Overview"},{"location":"cli/pltf_terraform/#pltf-terraform","text":"Terraform helpers (generate+init+tf commands)","title":"pltf terraform"},{"location":"cli/pltf_terraform/#options","text":"-h, --help help for terraform","title":"Options"},{"location":"cli/pltf_terraform/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks pltf terraform apply - Generate and apply Terraform for a spec pltf terraform destroy - Generate (if needed) and destroy Terraform for a spec pltf terraform force-unlock - Force unlock Terraform state for a spec pltf terraform graph - Generate a DOT graph for a spec (terraform graph or spec dependency graph) pltf terraform output - Show terraform outputs for a generated spec pltf terraform plan - Generate (if needed) and run terraform plan for a spec","title":"SEE ALSO"},{"location":"cli/pltf_terraform/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform_apply/","text":"pltf terraform apply Generate and apply Terraform for a spec Synopsis Render Terraform from an Environment or Service spec, ensure the backend bucket, then run 'terraform apply'. Supports Terraform-style flags like targets, lock timeout, parallelism, refresh control, and color toggles. Defaults to embedded modules and the standard output layout unless overridden. pltf terraform apply [flags] Examples pltf terraform apply -f env.yaml -e prod pltf terraform apply -f service.yaml -e dev -m ./modules -o ./.pltf/service/payments/dev --target=module.eks Options --auto-approve Pass -auto-approve to terraform apply -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for apply -i, --input Ask for input if necessary (default false) -l, --lock Lock state when locking is supported (default true) -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -p, --parallelism int Limit Terraform parallelism (0 = default) -r, --refresh Update state prior to actions (default true) -t, --target stringArray Optional Terraform target address (repeatable) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides. Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf terraform - Terraform helpers (generate+init+tf commands) Auto generated by spf13/cobra on 20-Dec-2025","title":"apply"},{"location":"cli/pltf_terraform_apply/#pltf-terraform-apply","text":"Generate and apply Terraform for a spec","title":"pltf terraform apply"},{"location":"cli/pltf_terraform_apply/#synopsis","text":"Render Terraform from an Environment or Service spec, ensure the backend bucket, then run 'terraform apply'. Supports Terraform-style flags like targets, lock timeout, parallelism, refresh control, and color toggles. Defaults to embedded modules and the standard output layout unless overridden. pltf terraform apply [flags]","title":"Synopsis"},{"location":"cli/pltf_terraform_apply/#examples","text":"pltf terraform apply -f env.yaml -e prod pltf terraform apply -f service.yaml -e dev -m ./modules -o ./.pltf/service/payments/dev --target=module.eks","title":"Examples"},{"location":"cli/pltf_terraform_apply/#options","text":"--auto-approve Pass -auto-approve to terraform apply -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for apply -i, --input Ask for input if necessary (default false) -l, --lock Lock state when locking is supported (default true) -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -p, --parallelism int Limit Terraform parallelism (0 = default) -r, --refresh Update state prior to actions (default true) -t, --target stringArray Optional Terraform target address (repeatable) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides.","title":"Options"},{"location":"cli/pltf_terraform_apply/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform_apply/#see-also","text":"pltf terraform - Terraform helpers (generate+init+tf commands)","title":"SEE ALSO"},{"location":"cli/pltf_terraform_apply/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform_destroy/","text":"pltf terraform destroy Generate (if needed) and destroy Terraform for a spec Synopsis Render Terraform if missing, then run 'terraform destroy'. Mirrors apply defaults (modules, output layout) and exposes Terraform knobs for targets, locking, refresh behavior, and color. pltf terraform destroy [flags] Examples pltf terraform destroy -f env.yaml -e prod pltf terraform destroy -f service.yaml -e dev --target=module.app-bucket Options --auto-approve Pass -auto-approve to terraform destroy -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for destroy -i, --input Ask for input if necessary (default false) -l, --lock Lock state when locking is supported (default true) -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -p, --parallelism int Limit Terraform parallelism (0 = default) -r, --refresh Update state prior to actions (default true) -t, --target stringArray Optional Terraform target address (repeatable) --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides. Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf terraform - Terraform helpers (generate+init+tf commands) Auto generated by spf13/cobra on 20-Dec-2025","title":"destroy"},{"location":"cli/pltf_terraform_destroy/#pltf-terraform-destroy","text":"Generate (if needed) and destroy Terraform for a spec","title":"pltf terraform destroy"},{"location":"cli/pltf_terraform_destroy/#synopsis","text":"Render Terraform if missing, then run 'terraform destroy'. Mirrors apply defaults (modules, output layout) and exposes Terraform knobs for targets, locking, refresh behavior, and color. pltf terraform destroy [flags]","title":"Synopsis"},{"location":"cli/pltf_terraform_destroy/#examples","text":"pltf terraform destroy -f env.yaml -e prod pltf terraform destroy -f service.yaml -e dev --target=module.app-bucket","title":"Examples"},{"location":"cli/pltf_terraform_destroy/#options","text":"--auto-approve Pass -auto-approve to terraform destroy -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for destroy -i, --input Ask for input if necessary (default false) -l, --lock Lock state when locking is supported (default true) -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -p, --parallelism int Limit Terraform parallelism (0 = default) -r, --refresh Update state prior to actions (default true) -t, --target stringArray Optional Terraform target address (repeatable) --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides.","title":"Options"},{"location":"cli/pltf_terraform_destroy/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform_destroy/#see-also","text":"pltf terraform - Terraform helpers (generate+init+tf commands)","title":"SEE ALSO"},{"location":"cli/pltf_terraform_destroy/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform_force-unlock/","text":"pltf terraform force-unlock Force unlock Terraform state for a spec Synopsis Run 'terraform force-unlock' against the generated stack. Use only to clear stale locks after verifying no active operation. pltf terraform force-unlock [flags] Examples pltf terraform force-unlock -f env.yaml -e prod --lock-id=12345 pltf terraform force-unlock -f service.yaml -e dev --lock-id=$(cat .terraform.tfstate.lock.info | jq -r .ID) Options -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for force-unlock -l, --lock Lock state when locking is supported (default true) --lock-id string Terraform lock ID to unlock -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf terraform - Terraform helpers (generate+init+tf commands) Auto generated by spf13/cobra on 20-Dec-2025","title":"force-unlock"},{"location":"cli/pltf_terraform_force-unlock/#pltf-terraform-force-unlock","text":"Force unlock Terraform state for a spec","title":"pltf terraform force-unlock"},{"location":"cli/pltf_terraform_force-unlock/#synopsis","text":"Run 'terraform force-unlock' against the generated stack. Use only to clear stale locks after verifying no active operation. pltf terraform force-unlock [flags]","title":"Synopsis"},{"location":"cli/pltf_terraform_force-unlock/#examples","text":"pltf terraform force-unlock -f env.yaml -e prod --lock-id=12345 pltf terraform force-unlock -f service.yaml -e dev --lock-id=$(cat .terraform.tfstate.lock.info | jq -r .ID)","title":"Examples"},{"location":"cli/pltf_terraform_force-unlock/#options","text":"-e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for force-unlock -l, --lock Lock state when locking is supported (default true) --lock-id string Terraform lock ID to unlock -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform","title":"Options"},{"location":"cli/pltf_terraform_force-unlock/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform_force-unlock/#see-also","text":"pltf terraform - Terraform helpers (generate+init+tf commands)","title":"SEE ALSO"},{"location":"cli/pltf_terraform_force-unlock/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform_graph/","text":"pltf terraform graph Generate a DOT graph for a spec (terraform graph or spec dependency graph) Synopsis Render Terraform (if needed) and produce a DOT graph. By default runs 'terraform graph' against the generated stack. With --mode=spec, emits a dependency graph from the env/service YAML (links and module references) without invoking Terraform. pltf terraform graph [flags] Examples pltf terraform graph -f env.yaml -e dev > graph.dot pltf terraform graph -f service.yaml -e dev --mode=spec --out-file=spec.dot Options -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for graph --mode string Graph mode: terraform (runs 'terraform graph') or spec (builds module dependency graph from YAML) (default \"terraform\") -m, --modules string Override modules root; defaults to embedded modules -o, --out string Output directory for generated Terraform (for terraform mode) --out-file string Write DOT output to a file instead of stdout -P, --plan-file string Use an existing plan file for terraform graph (passed as -plan=...) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Used for terraform mode generation. Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf terraform - Terraform helpers (generate+init+tf commands) Auto generated by spf13/cobra on 20-Dec-2025","title":"graph"},{"location":"cli/pltf_terraform_graph/#pltf-terraform-graph","text":"Generate a DOT graph for a spec (terraform graph or spec dependency graph)","title":"pltf terraform graph"},{"location":"cli/pltf_terraform_graph/#synopsis","text":"Render Terraform (if needed) and produce a DOT graph. By default runs 'terraform graph' against the generated stack. With --mode=spec, emits a dependency graph from the env/service YAML (links and module references) without invoking Terraform. pltf terraform graph [flags]","title":"Synopsis"},{"location":"cli/pltf_terraform_graph/#examples","text":"pltf terraform graph -f env.yaml -e dev > graph.dot pltf terraform graph -f service.yaml -e dev --mode=spec --out-file=spec.dot","title":"Examples"},{"location":"cli/pltf_terraform_graph/#options","text":"-e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for graph --mode string Graph mode: terraform (runs 'terraform graph') or spec (builds module dependency graph from YAML) (default \"terraform\") -m, --modules string Override modules root; defaults to embedded modules -o, --out string Output directory for generated Terraform (for terraform mode) --out-file string Write DOT output to a file instead of stdout -P, --plan-file string Use an existing plan file for terraform graph (passed as -plan=...) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Used for terraform mode generation.","title":"Options"},{"location":"cli/pltf_terraform_graph/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform_graph/#see-also","text":"pltf terraform - Terraform helpers (generate+init+tf commands)","title":"SEE ALSO"},{"location":"cli/pltf_terraform_graph/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform_output/","text":"pltf terraform output Show terraform outputs for a generated spec Synopsis Print Terraform outputs for the rendered stack. Supports JSON output for scripting and color toggles. pltf terraform output [flags] Examples pltf terraform output -f env.yaml -e prod pltf terraform output -f service.yaml -e dev --json Options -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for output -j, --json Render output as JSON -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -v, --var string Specific output name to show (optional) Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf terraform - Terraform helpers (generate+init+tf commands) Auto generated by spf13/cobra on 20-Dec-2025","title":"output"},{"location":"cli/pltf_terraform_output/#pltf-terraform-output","text":"Show terraform outputs for a generated spec","title":"pltf terraform output"},{"location":"cli/pltf_terraform_output/#synopsis","text":"Print Terraform outputs for the rendered stack. Supports JSON output for scripting and color toggles. pltf terraform output [flags]","title":"Synopsis"},{"location":"cli/pltf_terraform_output/#examples","text":"pltf terraform output -f env.yaml -e prod pltf terraform output -f service.yaml -e dev --json","title":"Examples"},{"location":"cli/pltf_terraform_output/#options","text":"-e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for output -j, --json Render output as JSON -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -v, --var string Specific output name to show (optional)","title":"Options"},{"location":"cli/pltf_terraform_output/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform_output/#see-also","text":"pltf terraform - Terraform helpers (generate+init+tf commands)","title":"SEE ALSO"},{"location":"cli/pltf_terraform_output/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_terraform_plan/","text":"pltf terraform plan Generate (if needed) and run terraform plan for a spec Synopsis Render Terraform and run 'terraform plan'. Supports detailed exit codes, plan file output, targets, locking, refresh toggles, and parallelism. Ideal for CI or local dry runs with the same generation defaults as apply. pltf terraform plan [flags] Examples pltf terraform plan -f env.yaml -e prod pltf terraform plan -f service.yaml -e dev --detailed-exitcode --plan-file=/tmp/plan.tfplan Options -d, --detailed-exitcode Use detailed exit codes for plan (2 = changes present) -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for plan -i, --input Ask for input if necessary (default false) -l, --lock Lock state when locking is supported (default true) -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -p, --parallelism int Limit Terraform parallelism (0 = default) -P, --plan-file string Write plan to a file (terraform -out) -r, --refresh Update state prior to actions (default true) -t, --target stringArray Optional Terraform target address (repeatable) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides. Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf terraform - Terraform helpers (generate+init+tf commands) Auto generated by spf13/cobra on 20-Dec-2025","title":"plan"},{"location":"cli/pltf_terraform_plan/#pltf-terraform-plan","text":"Generate (if needed) and run terraform plan for a spec","title":"pltf terraform plan"},{"location":"cli/pltf_terraform_plan/#synopsis","text":"Render Terraform and run 'terraform plan'. Supports detailed exit codes, plan file output, targets, locking, refresh toggles, and parallelism. Ideal for CI or local dry runs with the same generation defaults as apply. pltf terraform plan [flags]","title":"Synopsis"},{"location":"cli/pltf_terraform_plan/#examples","text":"pltf terraform plan -f env.yaml -e prod pltf terraform plan -f service.yaml -e dev --detailed-exitcode --plan-file=/tmp/plan.tfplan","title":"Examples"},{"location":"cli/pltf_terraform_plan/#options","text":"-d, --detailed-exitcode Use detailed exit codes for plan (2 = changes present) -e, --env string Environment key to render (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for plan -i, --input Ask for input if necessary (default false) -l, --lock Lock state when locking is supported (default true) -T, --lock-timeout string Lock timeout (e.g. 0s, 30s) -m, --modules string Override modules root; defaults to embedded modules -C, --no-color Disable color output -o, --out string Output directory for generated Terraform -p, --parallelism int Limit Terraform parallelism (0 = default) -P, --plan-file string Write plan to a file (terraform -out) -r, --refresh Update state prior to actions (default true) -t, --target stringArray Optional Terraform target address (repeatable) -v, --var stringArray Override variable as key=value; merges over vars and supports bool/int/JSON/list parsing. Can be repeated for multiple overrides.","title":"Options"},{"location":"cli/pltf_terraform_plan/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_terraform_plan/#see-also","text":"pltf terraform - Terraform helpers (generate+init+tf commands)","title":"SEE ALSO"},{"location":"cli/pltf_terraform_plan/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"cli/pltf_validate/","text":"pltf validate Validate an Environment or Service spec (auto-detects kind) Synopsis Parse a YAML spec, detect Environment vs Service, and run structural validation. Optionally assert that a specific environment key exists in both the environment file and the service envRef (for services). Lint suggestions are run alongside validation. pltf validate [flags] Examples pltf validate -f env.yaml pltf validate -f service.yaml -e dev Options -e, --env string Environment key to assert exists (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for validate Options inherited from parent commands --telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging SEE ALSO pltf - Platform toolkit for validating and generating Terraform stacks Auto generated by spf13/cobra on 20-Dec-2025","title":"validate"},{"location":"cli/pltf_validate/#pltf-validate","text":"Validate an Environment or Service spec (auto-detects kind)","title":"pltf validate"},{"location":"cli/pltf_validate/#synopsis","text":"Parse a YAML spec, detect Environment vs Service, and run structural validation. Optionally assert that a specific environment key exists in both the environment file and the service envRef (for services). Lint suggestions are run alongside validation. pltf validate [flags]","title":"Synopsis"},{"location":"cli/pltf_validate/#examples","text":"pltf validate -f env.yaml pltf validate -f service.yaml -e dev","title":"Examples"},{"location":"cli/pltf_validate/#options","text":"-e, --env string Environment key to assert exists (dev, prod, etc.) -f, --file string Path to the Environment or Service YAML file (default \"env.yaml\") -h, --help help for validate","title":"Options"},{"location":"cli/pltf_validate/#options-inherited-from-parent-commands","text":"--telemetry Enable anonymous telemetry (usage metrics). Currently a stub/no-op unless enabled. -V, --verbose Enable verbose logging","title":"Options inherited from parent commands"},{"location":"cli/pltf_validate/#see-also","text":"pltf - Platform toolkit for validating and generating Terraform stacks","title":"SEE ALSO"},{"location":"cli/pltf_validate/#auto-generated-by-spf13cobra-on-20-dec-2025","text":"","title":"Auto generated by spf13/cobra on 20-Dec-2025"},{"location":"concepts/environment/","text":"The common frame that powers your infrastructure. What is an Environment? Environment specs declare which cloud/account/region to configure. From this file, pltf can create the base resources (e.g., Kubernetes clusters, networks, IAM roles, ingress). You\u2019ll usually have one per staging/prod/QA; you can also create per-engineer or per-PR environments for isolated sandboxes. Definition (YAML) apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : myorg provider : aws # cloud provider labels : team : platform backend : type : s3 # s3|gcs|azurerm bucket : my-tf-bucket # optional; auto-named if omitted region : us-east-1 environments : prod : account : \"123456789012\" region : us-east-1 variables : base_domain : prod.example.com modules : - id : base type : aws_base - id : eks type : aws_eks inputs : cluster_name : var.base_domain Key points: - metadata sets name/org/provider and optional labels (become global tags). - backend.type can be s3|gcs|azurerm (independent of provider). backend.profile supports cross-account S3. - environments map holds per-env account/region/vars/secrets; pick one via --env or profile default_env . - modules are shared across services; use embedded catalog or source: custom to pull from your own root. State Storage pltf uses your cloud\u2019s native bucket for remote state (S3/GCS/Azurerm). One bucket per environment; state and metadata for the environment and its services live as separate objects. Backends are managed via backend.* and can be cross-cloud (e.g., Azure env with S3 backend). Next Steps Learn about Modules . Explore Service (coming soon) to connect workloads to environments.","title":"Environment"},{"location":"concepts/environment/#what-is-an-environment","text":"Environment specs declare which cloud/account/region to configure. From this file, pltf can create the base resources (e.g., Kubernetes clusters, networks, IAM roles, ingress). You\u2019ll usually have one per staging/prod/QA; you can also create per-engineer or per-PR environments for isolated sandboxes.","title":"What is an Environment?"},{"location":"concepts/environment/#definition-yaml","text":"apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : myorg provider : aws # cloud provider labels : team : platform backend : type : s3 # s3|gcs|azurerm bucket : my-tf-bucket # optional; auto-named if omitted region : us-east-1 environments : prod : account : \"123456789012\" region : us-east-1 variables : base_domain : prod.example.com modules : - id : base type : aws_base - id : eks type : aws_eks inputs : cluster_name : var.base_domain Key points: - metadata sets name/org/provider and optional labels (become global tags). - backend.type can be s3|gcs|azurerm (independent of provider). backend.profile supports cross-account S3. - environments map holds per-env account/region/vars/secrets; pick one via --env or profile default_env . - modules are shared across services; use embedded catalog or source: custom to pull from your own root.","title":"Definition (YAML)"},{"location":"concepts/environment/#state-storage","text":"pltf uses your cloud\u2019s native bucket for remote state (S3/GCS/Azurerm). One bucket per environment; state and metadata for the environment and its services live as separate objects. Backends are managed via backend.* and can be cross-cloud (e.g., Azure env with S3 backend).","title":"State Storage"},{"location":"concepts/environment/#next-steps","text":"Learn about Modules . Explore Service (coming soon) to connect workloads to environments.","title":"Next Steps"},{"location":"concepts/layer/","text":"An independently managed set of modules. What is a Layer? You can put all modules in an Environment file, but for finer granularity you define layers (Services). A layer provisions a set of modules together as a single unit and links to an Environment. Layers have: - a unique name - the environment(s) they run in (via metadata.ref / envRef ) - a list of modules (with optional links and inputs) When to use layers? Break down a large environment into separately maintained stacks. Share module definitions across multiple environments without duplicating YAML. Isolate per-service concerns (e.g., app plus its database) while reusing environment foundations. Definition (YAML) Example: a service (layer) for a Kubernetes workload with a database. apiVersion : platform.io/v1 kind : Service metadata : name : payments-api ref : ../env.yaml # link to Environment envRef : prod : {} # environment keys supported modules : - id : app type : aws_k8s_service inputs : public_uri : \"/payments\" image : \"ghcr.io/acme/payments:latest\" links : readwrite : - db - id : db type : aws_postgres inputs : instance_class : db.t3.medium Notes: - Service name maps to ${layer_name} placeholder; ${env_name} is the environment key. - Modules can link to each other ( links ) to consume outputs without manual wiring (e.g., ${module.db.db_host} ). - Per-environment overrides live under metadata.envRef . Next Steps See Environment for foundations. Explore module details in References .","title":"Layer"},{"location":"concepts/layer/#what-is-a-layer","text":"You can put all modules in an Environment file, but for finer granularity you define layers (Services). A layer provisions a set of modules together as a single unit and links to an Environment. Layers have: - a unique name - the environment(s) they run in (via metadata.ref / envRef ) - a list of modules (with optional links and inputs)","title":"What is a Layer?"},{"location":"concepts/layer/#when-to-use-layers","text":"Break down a large environment into separately maintained stacks. Share module definitions across multiple environments without duplicating YAML. Isolate per-service concerns (e.g., app plus its database) while reusing environment foundations.","title":"When to use layers?"},{"location":"concepts/layer/#definition-yaml","text":"Example: a service (layer) for a Kubernetes workload with a database. apiVersion : platform.io/v1 kind : Service metadata : name : payments-api ref : ../env.yaml # link to Environment envRef : prod : {} # environment keys supported modules : - id : app type : aws_k8s_service inputs : public_uri : \"/payments\" image : \"ghcr.io/acme/payments:latest\" links : readwrite : - db - id : db type : aws_postgres inputs : instance_class : db.t3.medium Notes: - Service name maps to ${layer_name} placeholder; ${env_name} is the environment key. - Modules can link to each other ( links ) to consume outputs without manual wiring (e.g., ${module.db.db_host} ). - Per-environment overrides live under metadata.envRef .","title":"Definition (YAML)"},{"location":"concepts/layer/#next-steps","text":"See Environment for foundations. Explore module details in References .","title":"Next Steps"},{"location":"concepts/module/","text":"A high-level building block to provision infrastructure. What is a Module? pltf includes an embedded library of modules you can connect to build your stack. Each module is a high-level construct that provisions the resources needed to achieve its goal (e.g., EKS cluster, S3 bucket, Postgres). Modules are described by module.yaml (type/provider/version/inputs/outputs) and referenced in your Environment or Service spec. Definition Modules have: - a type (e.g., aws_eks , aws_s3 ) - an optional id/name (so you can include multiple of the same type) - optional inputs (configuration) - optional links (to consume other module outputs) - optional source ( custom forces lookup in your custom modules root) Modules are defined inside the modules section of an Environment or Service. Minimal configuration We built pltf so you can provision a resource with a single line. Defaults follow best practices; customize only what you need. modules : - id : cluster type : aws_eks - id : db type : aws_postgres Extra configuration Override only the fields you care about; pltf uses recommended defaults otherwise. modules : - id : devcluster type : aws_eks inputs : node_instance_type : t3.medium max_nodes : 5 spot_instances : true - id : dbfrontend type : aws_postgres inputs : instance_class : db.t3.medium engine_version : \"12.4\" Links (module outputs as inputs) Modules can consume outputs from others using links or direct references like ${module.redis.cache_host} . modules : - id : redis type : aws_redis - id : airflow type : helm_chart inputs : repository : https://airflow.apache.org chart : airflow namespace : airflow chart_version : 1.4.0 values : brokerUrl : \"rediss://:${module.redis.cache_auth_token}@${module.redis.cache_host}\" Custom modules Generate module.yaml for your own Terraform module via pltf module init --path <module_dir> [--force] . Use source: custom in specs and provide --modules (or profile modules_root ) to load them. Terraform compatible pltf uses Terraform under the hood, so you\u2019re never locked in. Extend with your own Terraform or take the generated code with you. Next Steps Learn about Layer/Service (coming soon). Explore the module API in References and per-module pages.","title":"Module"},{"location":"concepts/module/#what-is-a-module","text":"pltf includes an embedded library of modules you can connect to build your stack. Each module is a high-level construct that provisions the resources needed to achieve its goal (e.g., EKS cluster, S3 bucket, Postgres). Modules are described by module.yaml (type/provider/version/inputs/outputs) and referenced in your Environment or Service spec.","title":"What is a Module?"},{"location":"concepts/module/#definition","text":"Modules have: - a type (e.g., aws_eks , aws_s3 ) - an optional id/name (so you can include multiple of the same type) - optional inputs (configuration) - optional links (to consume other module outputs) - optional source ( custom forces lookup in your custom modules root) Modules are defined inside the modules section of an Environment or Service.","title":"Definition"},{"location":"concepts/module/#minimal-configuration","text":"We built pltf so you can provision a resource with a single line. Defaults follow best practices; customize only what you need. modules : - id : cluster type : aws_eks - id : db type : aws_postgres","title":"Minimal configuration"},{"location":"concepts/module/#extra-configuration","text":"Override only the fields you care about; pltf uses recommended defaults otherwise. modules : - id : devcluster type : aws_eks inputs : node_instance_type : t3.medium max_nodes : 5 spot_instances : true - id : dbfrontend type : aws_postgres inputs : instance_class : db.t3.medium engine_version : \"12.4\"","title":"Extra configuration"},{"location":"concepts/module/#links-module-outputs-as-inputs","text":"Modules can consume outputs from others using links or direct references like ${module.redis.cache_host} . modules : - id : redis type : aws_redis - id : airflow type : helm_chart inputs : repository : https://airflow.apache.org chart : airflow namespace : airflow chart_version : 1.4.0 values : brokerUrl : \"rediss://:${module.redis.cache_auth_token}@${module.redis.cache_host}\"","title":"Links (module outputs as inputs)"},{"location":"concepts/module/#custom-modules","text":"Generate module.yaml for your own Terraform module via pltf module init --path <module_dir> [--force] . Use source: custom in specs and provide --modules (or profile modules_root ) to load them.","title":"Custom modules"},{"location":"concepts/module/#terraform-compatible","text":"pltf uses Terraform under the hood, so you\u2019re never locked in. Extend with your own Terraform or take the generated code with you.","title":"Terraform compatible"},{"location":"concepts/module/#next-steps","text":"Learn about Layer/Service (coming soon). Explore the module API in References and per-module pages.","title":"Next Steps"},{"location":"concepts/overview/","text":"pltf is Infrastructure-as-Code with a higher-level abstraction. You write configuration files, then run the pltf CLI (locally or in CI/CD) to connect to your cloud account and provision resources using Terraform under the hood. How It Works 1) Author YAML specs. 2) Run pltf preview|validate|generate|terraform ... . 3) The CLI renders Terraform (providers, backends, locals, remote state) and can execute Terraform for you. There are two primary spec types: Environment : Specifies cloud, account, and region. Running an Environment sets up the base resources (e.g., Kubernetes cluster, networks, IAM, ingress). Typical patterns: one per staging/prod/QA, or one per engineer/PR for isolated sandboxes. Service (Layer): Specifies the workload (often a microservice) and any non-Kubernetes resources it needs (e.g., databases, queues). pltf connects these seamlessly to the Environment. Environment and Service specs link via metadata.ref (path to env) and envRef (per-environment overrides).","title":"Overview"},{"location":"concepts/overview/#how-it-works","text":"1) Author YAML specs. 2) Run pltf preview|validate|generate|terraform ... . 3) The CLI renders Terraform (providers, backends, locals, remote state) and can execute Terraform for you. There are two primary spec types: Environment : Specifies cloud, account, and region. Running an Environment sets up the base resources (e.g., Kubernetes cluster, networks, IAM, ingress). Typical patterns: one per staging/prod/QA, or one per engineer/PR for isolated sandboxes. Service (Layer): Specifies the workload (often a microservice) and any non-Kubernetes resources it needs (e.g., databases, queues). pltf connects these seamlessly to the Environment. Environment and Service specs link via metadata.ref (path to env) and envRef (per-environment overrides).","title":"How It Works"},{"location":"example/airflow/","text":"","title":"Airflow"},{"location":"example/fsapp/","text":"","title":"Full Stack application"},{"location":"example/ml/","text":"","title":"ML Cluster"},{"location":"features/backends/","text":"Choose where Terraform state lives, independent of the target cloud. What it does Supports backend.type = s3|gcs|azurerm for any provider. Allows backend.profile for cross-account S3, region override, and container/resource_group for azurerm. Ensures the backend bucket/container exists before running Terraform. Example backend : type : s3 bucket : platform-tfstate region : us-east-1 profile : ops-account Notes Backends are rendered into backend.tf / terraform.tfvars alongside providers. You can point all clouds to a single backend (e.g., S3) if desired.","title":"Backends"},{"location":"features/backends/#what-it-does","text":"Supports backend.type = s3|gcs|azurerm for any provider. Allows backend.profile for cross-account S3, region override, and container/resource_group for azurerm. Ensures the backend bucket/container exists before running Terraform.","title":"What it does"},{"location":"features/backends/#example","text":"backend : type : s3 bucket : platform-tfstate region : us-east-1 profile : ops-account","title":"Example"},{"location":"features/backends/#notes","text":"Backends are rendered into backend.tf / terraform.tfvars alongside providers. You can point all clouds to a single backend (e.g., S3) if desired.","title":"Notes"},{"location":"features/custom-modules/","text":"Mix embedded modules with your own Terraform modules. What it does Uses the embedded catalog by default. Supports a custom modules root ( --modules or profile modules_root ). source: custom on a module forces lookup in your custom root; others fall back to embedded. pltf module init inspects a TF module and writes module.yaml metadata. Inventory commands: pltf module list|get -o table|json|yaml . Example modules : - name : app type : my_custom_service source : custom image : ghcr.io/acme/app:latest Notes Custom and embedded modules can coexist in the same spec. Module metadata ( module.yaml ) drives inputs/outputs and wiring; keep it committed.","title":"Custom Modules"},{"location":"features/custom-modules/#what-it-does","text":"Uses the embedded catalog by default. Supports a custom modules root ( --modules or profile modules_root ). source: custom on a module forces lookup in your custom root; others fall back to embedded. pltf module init inspects a TF module and writes module.yaml metadata. Inventory commands: pltf module list|get -o table|json|yaml .","title":"What it does"},{"location":"features/custom-modules/#example","text":"modules : - name : app type : my_custom_service source : custom image : ghcr.io/acme/app:latest","title":"Example"},{"location":"features/custom-modules/#notes","text":"Custom and embedded modules can coexist in the same spec. Module metadata ( module.yaml ) drives inputs/outputs and wiring; keep it committed.","title":"Notes"},{"location":"features/placeholders/","text":"Lightweight templating to keep specs DRY and wire modules together. What it does Intrinsics: ${env_name} , ${layer_name} . References: ${module.<id>.<output>} , ${parent.<output>} (services), ${var.<name>} . Auto-wires inputs to outputs when names match within scope; missing required values fail validation. Examples public_uri : \"https://${module.dns.domain}\" bucket_name : \"app-${env_name}\" max_nodes : \"${var.max_nodes}\" public_url : \"${parent.domain}/hello\" # in a service spec Notes Services can reference parent env outputs via ${parent.*} . Variables precedence: env vars \u2192 service envRef vars \u2192 CLI --var .","title":"Placeholders & Wiring"},{"location":"features/placeholders/#what-it-does","text":"Intrinsics: ${env_name} , ${layer_name} . References: ${module.<id>.<output>} , ${parent.<output>} (services), ${var.<name>} . Auto-wires inputs to outputs when names match within scope; missing required values fail validation.","title":"What it does"},{"location":"features/placeholders/#examples","text":"public_uri : \"https://${module.dns.domain}\" bucket_name : \"app-${env_name}\" max_nodes : \"${var.max_nodes}\" public_url : \"${parent.domain}/hello\" # in a service spec","title":"Examples"},{"location":"features/placeholders/#notes","text":"Services can reference parent env outputs via ${parent.*} . Variables precedence: env vars \u2192 service envRef vars \u2192 CLI --var .","title":"Notes"},{"location":"features/preview/","text":"Quickly inspect what will be generated without touching Terraform. What it does pltf preview reads your spec and shows provider, backend type, labels, and modules that will render. Auto-detects env vs service based on kind . Example pltf preview -f env.yaml -e prod Notes No cloud credentials needed; useful in CI or pre-commit checks. Pair with pltf validate for faster feedback before generation/apply.","title":"Preview"},{"location":"features/preview/#what-it-does","text":"pltf preview reads your spec and shows provider, backend type, labels, and modules that will render. Auto-detects env vs service based on kind .","title":"What it does"},{"location":"features/preview/#example","text":"pltf preview -f env.yaml -e prod","title":"Example"},{"location":"features/preview/#notes","text":"No cloud credentials needed; useful in CI or pre-commit checks. Pair with pltf validate for faster feedback before generation/apply.","title":"Notes"},{"location":"features/profiles/","text":"Set org-wide defaults so users type fewer flags and stay consistent. What it does Reads ~/.pltf/profile.yaml (or PLTF_PROFILE ) for defaults like modules_root , default_env , default_out , and telemetry . Lets you pick a custom modules root for all commands without repeating --modules . Allows a default environment name so --env can be omitted when unambiguous. Example profile modules_root : /infra/modules default_env : dev default_out : .pltf telemetry : false Usage Any CLI flags you pass override profile settings. Profiles are optional; when absent, embedded modules and CLI flags are used.","title":"Profiles & Defaults"},{"location":"features/profiles/#what-it-does","text":"Reads ~/.pltf/profile.yaml (or PLTF_PROFILE ) for defaults like modules_root , default_env , default_out , and telemetry . Lets you pick a custom modules root for all commands without repeating --modules . Allows a default environment name so --env can be omitted when unambiguous.","title":"What it does"},{"location":"features/profiles/#example-profile","text":"modules_root : /infra/modules default_env : dev default_out : .pltf telemetry : false","title":"Example profile"},{"location":"features/profiles/#usage","text":"Any CLI flags you pass override profile settings. Profiles are optional; when absent, embedded modules and CLI flags are used.","title":"Usage"},{"location":"features/secrets/","text":"Keep sensitive values out of specs and source control. What it does Secrets stay as Terraform variables and render to Kubernetes secrets for services. You declare secret keys in your spec; actual values are provided at runtime via environment variables or --var , typically sourced from your secret store/CI. Services receive secrets as env vars; no values are written into locals or files. Example (service) spec : secrets : db_password : {} # value supplied via env/CI modules : - type : aws_k8s_service name : app env_vars : - name : DB_PASSWORD value : \"${var.db_password}\" Runtime: PLTF_VAR_db_password = supersecret pltf terraform apply -f service.yaml -e prod Notes Prefer env/CI secret stores; do not commit secret values to specs or repos. Services restart to pick up new secret values after apply; plan rotations accordingly.","title":"Secrets"},{"location":"features/secrets/#what-it-does","text":"Secrets stay as Terraform variables and render to Kubernetes secrets for services. You declare secret keys in your spec; actual values are provided at runtime via environment variables or --var , typically sourced from your secret store/CI. Services receive secrets as env vars; no values are written into locals or files.","title":"What it does"},{"location":"features/secrets/#example-service","text":"spec : secrets : db_password : {} # value supplied via env/CI modules : - type : aws_k8s_service name : app env_vars : - name : DB_PASSWORD value : \"${var.db_password}\" Runtime: PLTF_VAR_db_password = supersecret pltf terraform apply -f service.yaml -e prod","title":"Example (service)"},{"location":"features/secrets/#notes","text":"Prefer env/CI secret stores; do not commit secret values to specs or repos. Services restart to pick up new secret values after apply; plan rotations accordingly.","title":"Notes"},{"location":"features/telemetry/","text":"Optional usage reporting. What it does Uses a global --telemetry flag (defaults from profile) to enable/disable future analytics. Currently a stub/no-op; reserved for opt-in reporting. Usage Set in profile: telemetry : false Or export PLTF_TELEMETRY=0 to disable.","title":"Telemetry"},{"location":"features/telemetry/#what-it-does","text":"Uses a global --telemetry flag (defaults from profile) to enable/disable future analytics. Currently a stub/no-op; reserved for opt-in reporting.","title":"What it does"},{"location":"features/telemetry/#usage","text":"Set in profile: telemetry : false Or export PLTF_TELEMETRY=0 to disable.","title":"Usage"},{"location":"features/terraform-commands/","text":"Run Terraform with consistent, auto-generated configs. What it does Commands live under pltf terraform plan|apply|destroy|output|force-unlock . Auto-generates Terraform (providers, backends, modules, outputs) before running TF. Ensures the backend bucket/container exists (S3/GCS/Azurerm) before init/apply. Passes through standard TF flags (targets, parallelism, lock, no-color, plan file, detailed exit codes). Examples pltf terraform plan -f service.yaml -e dev --detailed-exitcode --plan-file = /tmp/plan.tfplan pltf terraform apply -f env.yaml -e prod pltf terraform destroy -f env.yaml -e prod pltf terraform output -f service.yaml -e dev --json pltf terraform force-unlock -f env.yaml -e prod --lock-id = 12345 Notes Backends are decoupled from provider ( s3|gcs|azurerm supported). Common flags: --target/-t , --parallelism/-p , --lock/-l , --lock-timeout/-T , --no-color/-C , --input/-i , --refresh/-r , --plan-file/-P , --detailed-exitcode/-d , --json/-j . Uses the same generation path as pltf generate ; you can inspect the rendered TF in the output directory.","title":"Terraform commands"},{"location":"features/terraform-commands/#what-it-does","text":"Commands live under pltf terraform plan|apply|destroy|output|force-unlock . Auto-generates Terraform (providers, backends, modules, outputs) before running TF. Ensures the backend bucket/container exists (S3/GCS/Azurerm) before init/apply. Passes through standard TF flags (targets, parallelism, lock, no-color, plan file, detailed exit codes).","title":"What it does"},{"location":"features/terraform-commands/#examples","text":"pltf terraform plan -f service.yaml -e dev --detailed-exitcode --plan-file = /tmp/plan.tfplan pltf terraform apply -f env.yaml -e prod pltf terraform destroy -f env.yaml -e prod pltf terraform output -f service.yaml -e dev --json pltf terraform force-unlock -f env.yaml -e prod --lock-id = 12345","title":"Examples"},{"location":"features/terraform-commands/#notes","text":"Backends are decoupled from provider ( s3|gcs|azurerm supported). Common flags: --target/-t , --parallelism/-p , --lock/-l , --lock-timeout/-T , --no-color/-C , --input/-i , --refresh/-r , --plan-file/-P , --detailed-exitcode/-d , --json/-j . Uses the same generation path as pltf generate ; you can inspect the rendered TF in the output directory.","title":"Notes"},{"location":"features/terraform-generator/","text":"Render Terraform from your specs without applying. Ideal for reviews, CI, or migrating to raw Terraform. Overview pltf generate reads Environment or Service specs, auto-detects kind, and writes a self-contained Terraform directory (providers, backend, modules, outputs, versions). No cloud credentials are required to render. Generate Terraform Environment: pltf generate -f env.yaml -e prod -o .pltf/env/prod # produces: # .pltf/env/prod/ # \u251c\u2500 modules/ # copied/embedded module code used by this stack # \u251c\u2500 providers.tf # provider blocks + required versions # \u251c\u2500 backend.tf # state backend (s3|gcs|azurerm) # \u251c\u2500 locals.tf # computed locals/labels # \u251c\u2500 modules-*.tf # module instantiations # \u251c\u2500 outputs.tf # outputs # \u2514\u2500 versions.tf # provider/Terraform constraints Service: pltf generate -f service.yaml -e prod -o .pltf/service/payments/prod Migrate to Terraform Run pltf generate (or pltf terraform plan to generate+init) for each env/service stack. Commit the generated directory to VCS if you want to manage TF directly. Backends follow your spec; use backend.type ( s3|gcs|azurerm ) to point at your state bucket/container. Notes No provider calls during generation; safe to run without credentials. Supports custom modules ( source: custom ) alongside embedded ones; the generated modules/ directory is self-contained. Use pltf preview first to sanity check provider/backend/modules before generation.","title":"Terraform generator"},{"location":"features/terraform-generator/#overview","text":"pltf generate reads Environment or Service specs, auto-detects kind, and writes a self-contained Terraform directory (providers, backend, modules, outputs, versions). No cloud credentials are required to render.","title":"Overview"},{"location":"features/terraform-generator/#generate-terraform","text":"Environment: pltf generate -f env.yaml -e prod -o .pltf/env/prod # produces: # .pltf/env/prod/ # \u251c\u2500 modules/ # copied/embedded module code used by this stack # \u251c\u2500 providers.tf # provider blocks + required versions # \u251c\u2500 backend.tf # state backend (s3|gcs|azurerm) # \u251c\u2500 locals.tf # computed locals/labels # \u251c\u2500 modules-*.tf # module instantiations # \u251c\u2500 outputs.tf # outputs # \u2514\u2500 versions.tf # provider/Terraform constraints Service: pltf generate -f service.yaml -e prod -o .pltf/service/payments/prod","title":"Generate Terraform"},{"location":"features/terraform-generator/#migrate-to-terraform","text":"Run pltf generate (or pltf terraform plan to generate+init) for each env/service stack. Commit the generated directory to VCS if you want to manage TF directly. Backends follow your spec; use backend.type ( s3|gcs|azurerm ) to point at your state bucket/container.","title":"Migrate to Terraform"},{"location":"features/terraform-generator/#notes","text":"No provider calls during generation; safe to run without credentials. Supports custom modules ( source: custom ) alongside embedded ones; the generated modules/ directory is self-contained. Use pltf preview first to sanity check provider/backend/modules before generation.","title":"Notes"},{"location":"features/validation/","text":"Catch spec issues early before generation or apply. What it does pltf validate runs structural validation for Environment and Service specs. Built-in lint suggests labels and flags unused variables. Auto-detects kind (env/service) and applies the right checks. Example pltf validate -f env.yaml -e prod pltf validate -f service.yaml -e dev Notes Lint also runs implicitly during validate. Combine with pltf preview to sanity check providers/backends/modules.","title":"Validation & Lint"},{"location":"features/validation/#what-it-does","text":"pltf validate runs structural validation for Environment and Service specs. Built-in lint suggests labels and flags unused variables. Auto-detects kind (env/service) and applies the right checks.","title":"What it does"},{"location":"features/validation/#example","text":"pltf validate -f env.yaml -e prod pltf validate -f service.yaml -e dev","title":"Example"},{"location":"features/validation/#notes","text":"Lint also runs implicitly during validate. Combine with pltf preview to sanity check providers/backends/modules.","title":"Notes"},{"location":"features/variables/","text":"Reuse specs across environments and services with minimal templating. Overview Variables can be declared in your specs and overridden at runtime. They resolve into Terraform variables so you can keep a single spec and tune it per environment. Declare variables Define inputs in your spec and reference them with ${var.<name>} : variables : min_nodes : \"2\" max_nodes : \"5\" modules : - type : aws_eks min_nodes : \"${var.min_nodes}\" max_nodes : \"${var.max_nodes}\" Override at runtime Use repeatable --var flags or environment variables: pltf terraform apply -f env.yaml -e prod --var min_nodes = 3 --var max_nodes = 6 # or PLTF_VAR_min_nodes = 3 PLTF_VAR_max_nodes = 6 pltf generate -f env.yaml -e prod Environment-scoped variables Service specs can declare per-environment variables under envRef : envRef : name : prod path : ./env.yaml variables : containers : 5 modules : - type : aws_k8s_service min_containers : 1 max_containers : \"${var.containers}\" Parent outputs Services can use environment outputs via ${parent.<output>} : public_uri : \"${parent.domain}/hello\" Placeholder catalog ${env_name} , ${layer_name} (intrinsics) ${module.<module_name>.<output_name>} ${parent.<output_name>} (service only) ${var.<name>} (declared variables or CLI/env overrides) Notes Required variables without defaults must be provided via --var or env. Precedence: env vars \u2192 service envRef vars \u2192 CLI --var . Values stay in Terraform variables (not locals) to avoid leaking secrets.","title":"Variables"},{"location":"features/variables/#overview","text":"Variables can be declared in your specs and overridden at runtime. They resolve into Terraform variables so you can keep a single spec and tune it per environment.","title":"Overview"},{"location":"features/variables/#declare-variables","text":"Define inputs in your spec and reference them with ${var.<name>} : variables : min_nodes : \"2\" max_nodes : \"5\" modules : - type : aws_eks min_nodes : \"${var.min_nodes}\" max_nodes : \"${var.max_nodes}\"","title":"Declare variables"},{"location":"features/variables/#override-at-runtime","text":"Use repeatable --var flags or environment variables: pltf terraform apply -f env.yaml -e prod --var min_nodes = 3 --var max_nodes = 6 # or PLTF_VAR_min_nodes = 3 PLTF_VAR_max_nodes = 6 pltf generate -f env.yaml -e prod","title":"Override at runtime"},{"location":"features/variables/#environment-scoped-variables","text":"Service specs can declare per-environment variables under envRef : envRef : name : prod path : ./env.yaml variables : containers : 5 modules : - type : aws_k8s_service min_containers : 1 max_containers : \"${var.containers}\"","title":"Environment-scoped variables"},{"location":"features/variables/#parent-outputs","text":"Services can use environment outputs via ${parent.<output>} : public_uri : \"${parent.domain}/hello\"","title":"Parent outputs"},{"location":"features/variables/#placeholder-catalog","text":"${env_name} , ${layer_name} (intrinsics) ${module.<module_name>.<output_name>} ${parent.<output_name>} (service only) ${var.<name>} (declared variables or CLI/env overrides)","title":"Placeholder catalog"},{"location":"features/variables/#notes","text":"Required variables without defaults must be provided via --var or env. Precedence: env vars \u2192 service envRef vars \u2192 CLI --var . Values stay in Terraform variables (not locals) to avoid leaking secrets.","title":"Notes"},{"location":"getting-started/aws/","text":"This guide walks through provisioning a simple environment and service on AWS using pltf. You will create two YAML specs (environment and service), generate Terraform, and deploy. 1) Prerequisites Terraform v1.5+ (installed locally or via your CI) Docker (to build/push your images if needed) AWS credentials configured in your shell (e.g., aws configure or environment variables) (Optional) Custom modules directory if you want to bring your own modules Install pltf (Homebrew): brew tap yindia/pltf brew install pltf Or use the install script: /bin/bash -c \\\" $( curl -fsSL https://raw.githubusercontent.com/your-org/pltf/main/install.sh ) \\\" 2) Create an Environment spec Create env.yaml : apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : demo provider : aws labels : team : platform cost_center : shared environments : prod : account : \\\"123456789012\\\" region : us-east-1 backend : type : s3 # state backend (s3|gcs|azurerm) profile : default # optional cross-account profile variables : base_domain : prod.demo.internal cluster_name : demo-eks modules : - type : aws_base - type : aws_eks - type : aws_k8s_base What this does: - Configures AWS provider/region and S3 backend. - Creates networking, an EKS cluster, and base Kubernetes add-ons. - Exposes outputs (e.g., cluster endpoint/CA) for services. Generate and apply: pltf terraform plan -f env.yaml -e prod pltf terraform apply -f env.yaml -e prod First apply can take ~15 minutes. You can inspect outputs: pltf terraform output -f env.yaml -e prod --json 3) Create a Service spec Create service.yaml : apiVersion : platform.io/v1 kind : Service metadata : name : payments-api org : demo provider : aws envRef : name : prod path : ./env.yaml spec : variables : image : ghcr.io/demo/payments:latest modules : - name : app type : aws_k8s_service port : http : 8080 public_uri : \\\"/payments\\\" links : - app-bucket : [ write ] - name : app-bucket type : aws_s3 bucket_name : \\\"payments-${env_name}\\\" What this does: - Deploys a Kubernetes service on the EKS cluster created above. - Provisions an S3 bucket and links it to the app with write permissions (IRSA policy is generated). Generate and apply: pltf terraform plan -f service.yaml -e prod pltf terraform apply -f service.yaml -e prod 4) Access the service Find the load balancer host from outputs: pltf terraform output -f service.yaml -e prod | grep load_balancer_raw_dns Curl the path: curl http://<lb>/payments 5) Cleanup pltf terraform destroy -f service.yaml -e prod pltf terraform destroy -f env.yaml -e prod 6) Next Steps Review AWS architecture and module docs in the References section. Add more modules (RDS, Redis, SES, SNS, SQS) and link them for IAM/IRSA wiring. Use profiles ( ~/.pltf/profile.yaml ) to set default env/modules root and cross-account backends.","title":"AWS"},{"location":"getting-started/aws/#1-prerequisites","text":"Terraform v1.5+ (installed locally or via your CI) Docker (to build/push your images if needed) AWS credentials configured in your shell (e.g., aws configure or environment variables) (Optional) Custom modules directory if you want to bring your own modules Install pltf (Homebrew): brew tap yindia/pltf brew install pltf Or use the install script: /bin/bash -c \\\" $( curl -fsSL https://raw.githubusercontent.com/your-org/pltf/main/install.sh ) \\\"","title":"1) Prerequisites"},{"location":"getting-started/aws/#2-create-an-environment-spec","text":"Create env.yaml : apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : demo provider : aws labels : team : platform cost_center : shared environments : prod : account : \\\"123456789012\\\" region : us-east-1 backend : type : s3 # state backend (s3|gcs|azurerm) profile : default # optional cross-account profile variables : base_domain : prod.demo.internal cluster_name : demo-eks modules : - type : aws_base - type : aws_eks - type : aws_k8s_base What this does: - Configures AWS provider/region and S3 backend. - Creates networking, an EKS cluster, and base Kubernetes add-ons. - Exposes outputs (e.g., cluster endpoint/CA) for services. Generate and apply: pltf terraform plan -f env.yaml -e prod pltf terraform apply -f env.yaml -e prod First apply can take ~15 minutes. You can inspect outputs: pltf terraform output -f env.yaml -e prod --json","title":"2) Create an Environment spec"},{"location":"getting-started/aws/#3-create-a-service-spec","text":"Create service.yaml : apiVersion : platform.io/v1 kind : Service metadata : name : payments-api org : demo provider : aws envRef : name : prod path : ./env.yaml spec : variables : image : ghcr.io/demo/payments:latest modules : - name : app type : aws_k8s_service port : http : 8080 public_uri : \\\"/payments\\\" links : - app-bucket : [ write ] - name : app-bucket type : aws_s3 bucket_name : \\\"payments-${env_name}\\\" What this does: - Deploys a Kubernetes service on the EKS cluster created above. - Provisions an S3 bucket and links it to the app with write permissions (IRSA policy is generated). Generate and apply: pltf terraform plan -f service.yaml -e prod pltf terraform apply -f service.yaml -e prod","title":"3) Create a Service spec"},{"location":"getting-started/aws/#4-access-the-service","text":"Find the load balancer host from outputs: pltf terraform output -f service.yaml -e prod | grep load_balancer_raw_dns Curl the path: curl http://<lb>/payments","title":"4) Access the service"},{"location":"getting-started/aws/#5-cleanup","text":"pltf terraform destroy -f service.yaml -e prod pltf terraform destroy -f env.yaml -e prod","title":"5) Cleanup"},{"location":"getting-started/aws/#6-next-steps","text":"Review AWS architecture and module docs in the References section. Add more modules (RDS, Redis, SES, SNS, SQS) and link them for IAM/IRSA wiring. Use profiles ( ~/.pltf/profile.yaml ) to set default env/modules root and cross-account backends.","title":"6) Next Steps"},{"location":"getting-started/azure/","text":"Placeholder. Provide steps for Azure environment/service, backend (azurerm or s3/gcs), and custom modules.","title":"Azure"},{"location":"getting-started/gcp/","text":"Placeholder. Provide steps for GCP environment/service, backend (gcs or s3), and custom modules.","title":"Gcp"},{"location":"references/aws/","text":"The next generation of Infrastructure-as-Code: work with high-level constructs instead of getting lost in low-level cloud configuration. Status: active development; review generated code before applying. AWS is fully supported for environments, services, and modules. This page summarizes how the AWS provider, backends, and module wiring work in pltf. Provider and Backends Provider: Automatically injected; version comes from the central versions file. Region is taken from your env spec. Backends: You can store state in s3 , gcs , or azurerm even when targeting AWS. For cross-account S3, set backend.profile . Optional backend.region overrides the bucket region. Default tags: Labels in your env/service specs become global tags on the AWS provider. Example (Environment + Service) apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : pltf provider : aws labels : team : platform cost_center : shared environments : prod : account : \"556169302489\" region : us-east-1 backend : type : s3 profile : cross-account modules : - type : aws_base - type : aws_eks - type : aws_k8s_base apiVersion : platform.io/v1 kind : Service metadata : name : payments-api org : pltf provider : aws envRef : name : prod path : ../env.yaml spec : variables : image : ghcr.io/acme/payments:latest modules : - name : app type : aws_k8s_service port : http : 8080 links : - app-bucket : [ write ] - app-queue : [ consume ] - name : app-bucket type : aws_s3 bucket_name : \"payments-${env_name}\" - name : app-queue type : aws_sqs Modules and Fields Fields: Each module instance accepts inputs declared in its module.yaml . Only set what you need; defaults apply otherwise. Names: name is optional; defaults to the module type . Names are used for Terraform resource names and template placeholders. Types: type selects the module implementation. Embedded AWS modules are documented under \u201cModules (AWS)\u201d in the nav. Sources: Add source: custom to pull a module from your custom modules root; otherwise the embedded catalog is used. Linking Linking lets a module consume outputs of another: links : - app-bucket : [ read , write ] - app-queue : [ consume ] When links are present, pltf automatically renders IAM policies and (for Kubernetes) IRSA trusts. Supported AWS link targets include S3, SQS, SNS, SES, DynamoDB, RDS, and more via module metadata. Template placeholders ${env_name} and ${layer_name} become the resolved environment/service names. ${module.<module_name>.<output_name>} references another module\u2019s output. ${parent.<output_name>} references outputs from the parent environment when authoring a service. ${var.<name>} references variables defined in the spec or via --var . Useful commands pltf module list -o table \u2014 see available AWS modules. pltf module get aws_eks \u2014 inspect inputs/outputs. pltf generate -f env.yaml -e prod \u2014 render Terraform for AWS. pltf terraform plan/apply ... \u2014 generate + execute Terraform (plan/apply/destroy/output/force-unlock). See the module-specific pages under \u201cModules (AWS)\u201d for detailed inputs, outputs, and examples.","title":"Overview"},{"location":"references/aws/#provider-and-backends","text":"Provider: Automatically injected; version comes from the central versions file. Region is taken from your env spec. Backends: You can store state in s3 , gcs , or azurerm even when targeting AWS. For cross-account S3, set backend.profile . Optional backend.region overrides the bucket region. Default tags: Labels in your env/service specs become global tags on the AWS provider.","title":"Provider and Backends"},{"location":"references/aws/#example-environment-service","text":"apiVersion : platform.io/v1 kind : Environment metadata : name : example-aws org : pltf provider : aws labels : team : platform cost_center : shared environments : prod : account : \"556169302489\" region : us-east-1 backend : type : s3 profile : cross-account modules : - type : aws_base - type : aws_eks - type : aws_k8s_base apiVersion : platform.io/v1 kind : Service metadata : name : payments-api org : pltf provider : aws envRef : name : prod path : ../env.yaml spec : variables : image : ghcr.io/acme/payments:latest modules : - name : app type : aws_k8s_service port : http : 8080 links : - app-bucket : [ write ] - app-queue : [ consume ] - name : app-bucket type : aws_s3 bucket_name : \"payments-${env_name}\" - name : app-queue type : aws_sqs","title":"Example (Environment + Service)"},{"location":"references/aws/#modules-and-fields","text":"Fields: Each module instance accepts inputs declared in its module.yaml . Only set what you need; defaults apply otherwise. Names: name is optional; defaults to the module type . Names are used for Terraform resource names and template placeholders. Types: type selects the module implementation. Embedded AWS modules are documented under \u201cModules (AWS)\u201d in the nav. Sources: Add source: custom to pull a module from your custom modules root; otherwise the embedded catalog is used.","title":"Modules and Fields"},{"location":"references/aws/#linking","text":"Linking lets a module consume outputs of another: links : - app-bucket : [ read , write ] - app-queue : [ consume ] When links are present, pltf automatically renders IAM policies and (for Kubernetes) IRSA trusts. Supported AWS link targets include S3, SQS, SNS, SES, DynamoDB, RDS, and more via module metadata.","title":"Linking"},{"location":"references/aws/#template-placeholders","text":"${env_name} and ${layer_name} become the resolved environment/service names. ${module.<module_name>.<output_name>} references another module\u2019s output. ${parent.<output_name>} references outputs from the parent environment when authoring a service. ${var.<name>} references variables defined in the spec or via --var .","title":"Template placeholders"},{"location":"references/aws/#useful-commands","text":"pltf module list -o table \u2014 see available AWS modules. pltf module get aws_eks \u2014 inspect inputs/outputs. pltf generate -f env.yaml -e prod \u2014 render Terraform for AWS. pltf terraform plan/apply ... \u2014 generate + execute Terraform (plan/apply/destroy/output/force-unlock). See the module-specific pages under \u201cModules (AWS)\u201d for detailed inputs, outputs, and examples.","title":"Useful commands"},{"location":"references/aws_eks_access/","text":"How to access EKS clusters generated by pltf. Kubeconfig Fetch outputs: pltf terraform output -f env.yaml -e <env> --json | jq '.aws_eks' Note k8s_cluster_name , k8s_endpoint , and k8s_ca_data . Update kubeconfig: aws eks update-kubeconfig \\ --region <region> \\ --name <cluster> \\ --profile <aws-profile-if-needed> Use the same AWS profile that has access to the environment account (or backend profile if you share credentials). Generated Terraform already configures Kubernetes and Helm providers using these outputs when you run pltf terraform plan/apply . AWS IAM to Kubernetes RBAC EKS uses the aws-auth ConfigMap in kube-system to map IAM users/roles to Kubernetes groups. Example aws-auth data: apiVersion : v1 data : mapRoles : | - groups: ['system:bootstrappers', 'system:nodes'] rolearn: arn:aws:iam::ACCOUNT_ID:role/pltf-live-example-dev-eks-default-node-group username: system:node:{{EC2PrivateDNSName}} - groups: ['system:masters'] rolearn: arn:aws:iam::ACCOUNT_ID:role/demo-admin username: pltf-managed mapUsers : | - groups: ['system:masters'] userarn: arn:aws:iam::ACCOUNT_ID:user/demo-admin username: pltf-managed Fields: - rolearn / userarn : IAM principal. - username : friendly alias. - groups : Kubernetes RBAC groups (use system:masters for admin). Granting access via pltf Use admin_arns on aws_k8s_base to inject IAM admins without editing Kubernetes directly: modules : - type : aws_k8s_base admin_arns : - \"arn:aws:iam::123456789012:user/platform-admin\" - \"arn:aws:iam::123456789012:role/platform-admin\" Viewing RBAC bindings kubectl get clusterrolebindings -o json | jq -r '.items[] | select(.subjects[0].kind==\\\"Group\\\") | .metadata.name' kubectl get rolebindings -A -o json | jq -r '.items[] | select(.subjects[0].kind==\\\"Group\\\") | .metadata.name' Example cluster role binding: apiVersion : rbac.authorization.k8s.io/v1 kind : ClusterRoleBinding metadata : name : my-cluster-role-binding roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : system:discovery subjects : - apiGroup : rbac.authorization.k8s.io kind : Group name : my-group This grants members of my-group the permissions of system:discovery across all namespaces. Summary Use aws eks update-kubeconfig with cluster outputs to get access. Add IAM admins via admin_arns on aws_k8s_base (maps to system:masters ). For custom RBAC, edit aws-auth or create your own role/cluster role bindings.","title":"EKS Access"},{"location":"references/aws_eks_access/#kubeconfig","text":"Fetch outputs: pltf terraform output -f env.yaml -e <env> --json | jq '.aws_eks' Note k8s_cluster_name , k8s_endpoint , and k8s_ca_data . Update kubeconfig: aws eks update-kubeconfig \\ --region <region> \\ --name <cluster> \\ --profile <aws-profile-if-needed> Use the same AWS profile that has access to the environment account (or backend profile if you share credentials). Generated Terraform already configures Kubernetes and Helm providers using these outputs when you run pltf terraform plan/apply .","title":"Kubeconfig"},{"location":"references/aws_eks_access/#aws-iam-to-kubernetes-rbac","text":"EKS uses the aws-auth ConfigMap in kube-system to map IAM users/roles to Kubernetes groups. Example aws-auth data: apiVersion : v1 data : mapRoles : | - groups: ['system:bootstrappers', 'system:nodes'] rolearn: arn:aws:iam::ACCOUNT_ID:role/pltf-live-example-dev-eks-default-node-group username: system:node:{{EC2PrivateDNSName}} - groups: ['system:masters'] rolearn: arn:aws:iam::ACCOUNT_ID:role/demo-admin username: pltf-managed mapUsers : | - groups: ['system:masters'] userarn: arn:aws:iam::ACCOUNT_ID:user/demo-admin username: pltf-managed Fields: - rolearn / userarn : IAM principal. - username : friendly alias. - groups : Kubernetes RBAC groups (use system:masters for admin).","title":"AWS IAM to Kubernetes RBAC"},{"location":"references/aws_eks_access/#granting-access-via-pltf","text":"Use admin_arns on aws_k8s_base to inject IAM admins without editing Kubernetes directly: modules : - type : aws_k8s_base admin_arns : - \"arn:aws:iam::123456789012:user/platform-admin\" - \"arn:aws:iam::123456789012:role/platform-admin\"","title":"Granting access via pltf"},{"location":"references/aws_eks_access/#viewing-rbac-bindings","text":"kubectl get clusterrolebindings -o json | jq -r '.items[] | select(.subjects[0].kind==\\\"Group\\\") | .metadata.name' kubectl get rolebindings -A -o json | jq -r '.items[] | select(.subjects[0].kind==\\\"Group\\\") | .metadata.name' Example cluster role binding: apiVersion : rbac.authorization.k8s.io/v1 kind : ClusterRoleBinding metadata : name : my-cluster-role-binding roleRef : apiGroup : rbac.authorization.k8s.io kind : ClusterRole name : system:discovery subjects : - apiGroup : rbac.authorization.k8s.io kind : Group name : my-group This grants members of my-group the permissions of system:discovery across all namespaces.","title":"Viewing RBAC bindings"},{"location":"references/aws_eks_access/#summary","text":"Use aws eks update-kubeconfig with cluster outputs to get access. Add IAM admins via admin_arns on aws_k8s_base (maps to system:masters ). For custom RBAC, edit aws-auth or create your own role/cluster role bindings.","title":"Summary"},{"location":"references/aws_eks_upgrade/","text":"How to upgrade the version of your EKS cluster created by pltf. Overview EKS does not auto-upgrade clusters. Upgrade one minor version at a time (e.g., 1.24 \u2192 1.25). Steps below use the AWS console; CLI works too. Step 1: Control Plane Open the EKS cluster (correct region). Click Update now on the control plane. Select the next Kubernetes version and start the update. Important: During control plane upgrade (~20 min) avoid new deploys or kubectl changes. Running workloads keep serving traffic. Step 2: Node Groups Go to Configuration \u2192 Compute . For each managed node group, click Update now . Use Rolling update strategy and start the upgrade. Important: Nodes are replaced. If ingress is not HA, expect brief downtime while pods reschedule. Upgrade node groups one at a time. Step 3: Pin versions in specs After upgrading, pin the new versions so future applies stay consistent: modules : - type : aws_eks k8s_version : \"1.25\" - type : aws_nodegroup name : default k8s_version : \"1.25\" Then: pltf terraform plan -f env.yaml -e prod pltf terraform apply -f env.yaml -e prod Breaking Changes Review Kubernetes API deprecations for your target version. Ensure add-ons (CNI, metrics, ingress) are compatible. For multi-hop upgrades (e.g., 1.22 \u2192 1.24), step through each minor version. References AWS: https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html Versions: https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html","title":"EKS Upgrade"},{"location":"references/aws_eks_upgrade/#overview","text":"EKS does not auto-upgrade clusters. Upgrade one minor version at a time (e.g., 1.24 \u2192 1.25). Steps below use the AWS console; CLI works too.","title":"Overview"},{"location":"references/aws_eks_upgrade/#step-1-control-plane","text":"Open the EKS cluster (correct region). Click Update now on the control plane. Select the next Kubernetes version and start the update. Important: During control plane upgrade (~20 min) avoid new deploys or kubectl changes. Running workloads keep serving traffic.","title":"Step 1: Control Plane"},{"location":"references/aws_eks_upgrade/#step-2-node-groups","text":"Go to Configuration \u2192 Compute . For each managed node group, click Update now . Use Rolling update strategy and start the upgrade. Important: Nodes are replaced. If ingress is not HA, expect brief downtime while pods reschedule. Upgrade node groups one at a time.","title":"Step 2: Node Groups"},{"location":"references/aws_eks_upgrade/#step-3-pin-versions-in-specs","text":"After upgrading, pin the new versions so future applies stay consistent: modules : - type : aws_eks k8s_version : \"1.25\" - type : aws_nodegroup name : default k8s_version : \"1.25\" Then: pltf terraform plan -f env.yaml -e prod pltf terraform apply -f env.yaml -e prod","title":"Step 3: Pin versions in specs"},{"location":"references/aws_eks_upgrade/#breaking-changes","text":"Review Kubernetes API deprecations for your target version. Ensure add-ons (CNI, metrics, ingress) are compatible. For multi-hop upgrades (e.g., 1.22 \u2192 1.24), step through each minor version.","title":"Breaking Changes"},{"location":"references/aws_eks_upgrade/#references","text":"AWS: https://docs.aws.amazon.com/eks/latest/userguide/update-cluster.html Versions: https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html","title":"References"},{"location":"references/azure/","text":"Azure Reference Placeholder. Document provider settings, backend options (azurerm/s3/gcs), and guidance for custom modules or future Azure modules.","title":"Azure Reference"},{"location":"references/azure/#azure-reference","text":"Placeholder. Document provider settings, backend options (azurerm/s3/gcs), and guidance for custom modules or future Azure modules.","title":"Azure Reference"},{"location":"references/gcp/","text":"Placeholder. Document provider settings, backend options (gcs or s3), and guidance for custom modules.","title":"Gcp"},{"location":"references/modules/aws_base/","text":"Provision networking (VPC), subnets across AZs, flow logs, NAT, and a default KMS key + log bucket for the environment. What it does Creates a new VPC (or imports an existing one) with public/private subnets across three AZs. Adds internet/NAT gateways and route tables for public/private egress. Enables VPC flow logs to the log bucket and provisions a default KMS key. Creates a log bucket for access/flow logs used by other modules. Fields Name Description Default Required private_ipv4_cidr_blocks Cidr blocks for private subnets. One for each desired AZ ['10.0.128.0/21', '10.0.136.0/21', '10.0.144.0/21'] False private_subnet_ids List of pre-existing private subnets to use instead of creating new subnets for pltf. Required when var.vpc_id is set. False public_ipv4_cidr_blocks Cidr blocks for public subnets. One for each desired AZ ['10.0.0.0/21', '10.0.8.0/21', '10.0.16.0/21'] False public_subnet_ids List of pre-existing public subnets to use instead of creating new subnets for pltf. Required when var.vpc_id is set. False total_ipv4_cidr_block Cidr block to reserve for whole vpc 10.0.0.0/16 False vpc_id The ID of an pre-existing VPC to use instead of creating a new VPC for pltf False vpc_log_retention 90 False Bring your own VPC To use an existing VPC, set vpc_id , public_subnet_ids , and private_subnet_ids . Public subnets must route to an internet gateway and assign public IPs. Private subnets must route 0.0.0.0/0 to a NAT gateway with a public IP. Misconfigured routes may yield Terraform errors like \"No routes matching supplied arguments found in Route Table\". IPv6 imports are not validated; dual-stack may work but is not verified. Outputs Name Description kms_account_key_arn ARN of the default KMS key for environment resources kms_account_key_id ID of the default KMS key private_subnet_ids Private subnet IDs provisioned/imported public_nat_ips Elastic IPs of NAT gateways public_subnets_ids Public subnet IDs provisioned/imported s3_log_bucket_name Name of the environment log bucket vpc_id VPC ID provisioned/imported","title":"aws_base"},{"location":"references/modules/aws_base/#what-it-does","text":"Creates a new VPC (or imports an existing one) with public/private subnets across three AZs. Adds internet/NAT gateways and route tables for public/private egress. Enables VPC flow logs to the log bucket and provisions a default KMS key. Creates a log bucket for access/flow logs used by other modules.","title":"What it does"},{"location":"references/modules/aws_base/#fields","text":"Name Description Default Required private_ipv4_cidr_blocks Cidr blocks for private subnets. One for each desired AZ ['10.0.128.0/21', '10.0.136.0/21', '10.0.144.0/21'] False private_subnet_ids List of pre-existing private subnets to use instead of creating new subnets for pltf. Required when var.vpc_id is set. False public_ipv4_cidr_blocks Cidr blocks for public subnets. One for each desired AZ ['10.0.0.0/21', '10.0.8.0/21', '10.0.16.0/21'] False public_subnet_ids List of pre-existing public subnets to use instead of creating new subnets for pltf. Required when var.vpc_id is set. False total_ipv4_cidr_block Cidr block to reserve for whole vpc 10.0.0.0/16 False vpc_id The ID of an pre-existing VPC to use instead of creating a new VPC for pltf False vpc_log_retention 90 False","title":"Fields"},{"location":"references/modules/aws_base/#bring-your-own-vpc","text":"To use an existing VPC, set vpc_id , public_subnet_ids , and private_subnet_ids . Public subnets must route to an internet gateway and assign public IPs. Private subnets must route 0.0.0.0/0 to a NAT gateway with a public IP. Misconfigured routes may yield Terraform errors like \"No routes matching supplied arguments found in Route Table\". IPv6 imports are not validated; dual-stack may work but is not verified.","title":"Bring your own VPC"},{"location":"references/modules/aws_base/#outputs","text":"Name Description kms_account_key_arn ARN of the default KMS key for environment resources kms_account_key_id ID of the default KMS key private_subnet_ids Private subnet IDs provisioned/imported public_nat_ips Elastic IPs of NAT gateways public_subnets_ids Public subnet IDs provisioned/imported s3_log_bucket_name Name of the environment log bucket vpc_id VPC ID provisioned/imported","title":"Outputs"},{"location":"references/modules/aws_dns/","text":"Creates a Route53 hosted zone and ACM certificate with DNS validation, wiring records for ingress/load balancers. What it does Creates Route53 hosted zone and ACM cert with DNS validation or import. Exposes NS records and cert ARN for downstream modules. Fields Name Description Default Required cert_chain_included False False delegated False False domain True external_cert_arn False force_update False False upload_cert False False Outputs Name Description cert_arn ACM certificate ARN (created/imported/external). domain Domain name of the hosted zone. name_servers Delegated name servers. zone_id Route53 hosted zone ID.","title":"aws_dns"},{"location":"references/modules/aws_dns/#what-it-does","text":"Creates Route53 hosted zone and ACM cert with DNS validation or import. Exposes NS records and cert ARN for downstream modules.","title":"What it does"},{"location":"references/modules/aws_dns/#fields","text":"Name Description Default Required cert_chain_included False False delegated False False domain True external_cert_arn False force_update False False upload_cert False False","title":"Fields"},{"location":"references/modules/aws_dns/#outputs","text":"Name Description cert_arn ACM certificate ARN (created/imported/external). domain Domain name of the hosted zone. name_servers Delegated name servers. zone_id Route53 hosted zone ID.","title":"Outputs"},{"location":"references/modules/aws_documentdb/","text":"Provision a DocumentDB cluster with subnet groups, encryption, backups, and security groups in the base VPC. What it does Creates a DocumentDB cluster with configurable engine version and instance count. Uses subnet groups and security groups from the VPC; enables encryption. Supports deletion protection and exposes host/user/password outputs. Fields Name Description Default Required deletion_protection A value that indicates whether the DB cluster has deletion protection enabled. The database can't be deleted when deletion protection is enabled. False False engine_version 4.0.0 False instance_class db.r5.large False instance_count Number of Instances for aws_docdb_cluster_instance 1 False Outputs Name Description db_host Cluster endpoint. db_password Master password. db_user Master username.","title":"aws_documentdb"},{"location":"references/modules/aws_documentdb/#what-it-does","text":"Creates a DocumentDB cluster with configurable engine version and instance count. Uses subnet groups and security groups from the VPC; enables encryption. Supports deletion protection and exposes host/user/password outputs.","title":"What it does"},{"location":"references/modules/aws_documentdb/#fields","text":"Name Description Default Required deletion_protection A value that indicates whether the DB cluster has deletion protection enabled. The database can't be deleted when deletion protection is enabled. False False engine_version 4.0.0 False instance_class db.r5.large False instance_count Number of Instances for aws_docdb_cluster_instance 1 False","title":"Fields"},{"location":"references/modules/aws_documentdb/#outputs","text":"Name Description db_host Cluster endpoint. db_password Master password. db_user Master username.","title":"Outputs"},{"location":"references/modules/aws_dynamodb/","text":"Creates a DynamoDB table with encryption, throughput settings, TTL, and optional point-in-time recovery. What it does Creates a DynamoDB table with server-side encryption and customizable billing mode. Supports provisioned throughput settings and TTL via attributes. Exposes table ARN/ID and KMS key details. Fields Name Description Default Required attributes True billing_mode PROVISIONED False hash_key False range_key False read_capacity 20 False write_capacity 20 False Outputs Name Description kms_arn KMS key ARN used for encryption. kms_id KMS key ID used for encryption. table_arn Table ARN. table_id Table name/ID.","title":"aws_dynamodb"},{"location":"references/modules/aws_dynamodb/#what-it-does","text":"Creates a DynamoDB table with server-side encryption and customizable billing mode. Supports provisioned throughput settings and TTL via attributes. Exposes table ARN/ID and KMS key details.","title":"What it does"},{"location":"references/modules/aws_dynamodb/#fields","text":"Name Description Default Required attributes True billing_mode PROVISIONED False hash_key False range_key False read_capacity 20 False write_capacity 20 False","title":"Fields"},{"location":"references/modules/aws_dynamodb/#outputs","text":"Name Description kms_arn KMS key ARN used for encryption. kms_id KMS key ID used for encryption. table_arn Table ARN. table_id Table name/ID.","title":"Outputs"},{"location":"references/modules/aws_eks/","text":"Creates an EKS control plane in private subnets, configurable Kubernetes version, logging, and OIDC provider for IRSA. What it does Provisions the EKS control plane in private subnets with security groups. Creates an OIDC provider for IRSA and enables control-plane logging. Stands up a default managed nodegroup with scaling/min/max and optional spot. Fields Name Description Default Required ami_type AL2023_x86_64_STANDARD False cluster_name True control_plane_security_groups List of security groups to give control plane access to [] False eks_log_retention 7 False enable_metrics True k8s_version 1.21 False kms_account_key_arn True max_nodes 5 False min_nodes 3 False node_disk_size 20 False node_instance_type t3.medium False node_launch_template {} False private_subnet_ids True spot_instances False False vpc_id True Outputs Name Description k8s_ca_data Cluster CA data (base64). k8s_cluster_name EKS cluster name. k8s_endpoint EKS API endpoint. k8s_node_group_security_id Security group ID for nodes. k8s_openid_provider_arn OIDC provider ARN for IRSA. k8s_openid_provider_url OIDC provider URL. k8s_version Kubernetes version.","title":"aws_eks"},{"location":"references/modules/aws_eks/#what-it-does","text":"Provisions the EKS control plane in private subnets with security groups. Creates an OIDC provider for IRSA and enables control-plane logging. Stands up a default managed nodegroup with scaling/min/max and optional spot.","title":"What it does"},{"location":"references/modules/aws_eks/#fields","text":"Name Description Default Required ami_type AL2023_x86_64_STANDARD False cluster_name True control_plane_security_groups List of security groups to give control plane access to [] False eks_log_retention 7 False enable_metrics True k8s_version 1.21 False kms_account_key_arn True max_nodes 5 False min_nodes 3 False node_disk_size 20 False node_instance_type t3.medium False node_launch_template {} False private_subnet_ids True spot_instances False False vpc_id True","title":"Fields"},{"location":"references/modules/aws_eks/#outputs","text":"Name Description k8s_ca_data Cluster CA data (base64). k8s_cluster_name EKS cluster name. k8s_endpoint EKS API endpoint. k8s_node_group_security_id Security group ID for nodes. k8s_openid_provider_arn OIDC provider ARN for IRSA. k8s_openid_provider_url OIDC provider URL. k8s_version Kubernetes version.","title":"Outputs"},{"location":"references/modules/aws_iam_policy/","text":"Defines IAM policies (inline or managed) to attach to roles/users created by other modules. What it does Creates a standalone IAM policy from a JSON document for reuse. Fields Name Description Default Required file Json file path containing the Policy False Outputs Name Description policy_arn IAM policy ARN. policy_id IAM policy ID. policy_name IAM policy name.","title":"aws_iam_policy"},{"location":"references/modules/aws_iam_policy/#what-it-does","text":"Creates a standalone IAM policy from a JSON document for reuse.","title":"What it does"},{"location":"references/modules/aws_iam_policy/#fields","text":"Name Description Default Required file Json file path containing the Policy False","title":"Fields"},{"location":"references/modules/aws_iam_policy/#outputs","text":"Name Description policy_arn IAM policy ARN. policy_id IAM policy ID. policy_name IAM policy name.","title":"Outputs"},{"location":"references/modules/aws_iam_role/","text":"Creates IAM roles with inline/managed policies and OIDC trust for Kubernetes service accounts (IRSA). What it does Creates an IAM role with inline policy and optional managed policies. Supports IRSA/OIDC trust for Kubernetes service accounts and trust for other IAM principals. Auto-generates least-privilege policies from links when used with supported modules. Fields Name Description Default Required allowed_iams [] False allowed_k8s_services [] False extra_iam_policies [] False iam_policy True kubernetes_trusts [] False links [] False Outputs Name Description role_arn IAM role ARN.","title":"aws_iam_role"},{"location":"references/modules/aws_iam_role/#what-it-does","text":"Creates an IAM role with inline policy and optional managed policies. Supports IRSA/OIDC trust for Kubernetes service accounts and trust for other IAM principals. Auto-generates least-privilege policies from links when used with supported modules.","title":"What it does"},{"location":"references/modules/aws_iam_role/#fields","text":"Name Description Default Required allowed_iams [] False allowed_k8s_services [] False extra_iam_policies [] False iam_policy True kubernetes_trusts [] False links [] False","title":"Fields"},{"location":"references/modules/aws_iam_role/#outputs","text":"Name Description role_arn IAM role ARN.","title":"Outputs"},{"location":"references/modules/aws_iam_user/","text":"Creates IAM users with optional access keys and managed/inline policy attachments. What it does Creates an IAM user with inline/managed policies. Optionally auto-generates policies from links and returns access keys if created. Fields Name Description Default Required extra_iam_policies [] False iam_policy True links [] False Outputs Name Description user_arn IAM user ARN.","title":"aws_iam_user"},{"location":"references/modules/aws_iam_user/#what-it-does","text":"Creates an IAM user with inline/managed policies. Optionally auto-generates policies from links and returns access keys if created.","title":"What it does"},{"location":"references/modules/aws_iam_user/#fields","text":"Name Description Default Required extra_iam_policies [] False iam_policy True links [] False","title":"Fields"},{"location":"references/modules/aws_iam_user/#outputs","text":"Name Description user_arn IAM user ARN.","title":"Outputs"},{"location":"references/modules/aws_mysql/","text":"Provisions an Aurora MySQL cluster with subnet group, encryption, backups, and optional multi-AZ. What it does Provisions an Aurora MySQL cluster in private subnets with encryption. Supports multi-AZ, backups, retention, and public accessibility toggle. Exposes writer/reader endpoints and security/subnet group metadata. Fields Name Description Default Required backup_retention_days How many days to keep the backup retention True db_name app False engine_version 5.7.mysql_aurora.2.04.2 False instance_class db.t3.medium False multi_az False False safety False False Outputs Name Description db_host db_name db_password db_user","title":"aws_mysql"},{"location":"references/modules/aws_mysql/#what-it-does","text":"Provisions an Aurora MySQL cluster in private subnets with encryption. Supports multi-AZ, backups, retention, and public accessibility toggle. Exposes writer/reader endpoints and security/subnet group metadata.","title":"What it does"},{"location":"references/modules/aws_mysql/#fields","text":"Name Description Default Required backup_retention_days How many days to keep the backup retention True db_name app False engine_version 5.7.mysql_aurora.2.04.2 False instance_class db.t3.medium False multi_az False False safety False False","title":"Fields"},{"location":"references/modules/aws_mysql/#outputs","text":"Name Description db_host db_name db_password db_user","title":"Outputs"},{"location":"references/modules/aws_nodegroup/","text":"Managed node group for EKS with scaling limits, instance type, disk size, and optional spot instances. What it does Adds an EKS managed node group with scaling limits and instance type/disk controls. Supports spot instances and custom labels/taints (via launch template inputs if set). Fields Name Description Default Required ami_type AL2023_x86_64_STANDARD False autoscaling_tags {} False labels {} False max_nodes 15 False min_nodes 3 False node_disk_size 20 False node_instance_type t3.medium False spot_instances False False taints [] False use_gpu False False Outputs Name Description","title":"aws_nodegroup"},{"location":"references/modules/aws_nodegroup/#what-it-does","text":"Adds an EKS managed node group with scaling limits and instance type/disk controls. Supports spot instances and custom labels/taints (via launch template inputs if set).","title":"What it does"},{"location":"references/modules/aws_nodegroup/#fields","text":"Name Description Default Required ami_type AL2023_x86_64_STANDARD False autoscaling_tags {} False labels {} False max_nodes 15 False min_nodes 3 False node_disk_size 20 False node_instance_type t3.medium False spot_instances False False taints [] False use_gpu False False","title":"Fields"},{"location":"references/modules/aws_nodegroup/#outputs","text":"Name Description","title":"Outputs"},{"location":"references/modules/aws_postgres/","text":"Provisions an Aurora Postgres cluster with subnet group, encryption, backups, and optional multi-AZ. What it does Provisions an Aurora Postgres cluster in private subnets with encryption. Supports multi-AZ, backups, retention, and public accessibility toggle. Exposes writer/reader endpoints and security/subnet group metadata. Fields Name Description Default Required backup_retention_days How many days to keep the backup retention True create_global_database True database_name True engine_version 11.9 False existing_global_database_id True extra_security_groups_ids True instance_class db.t3.medium False multi_az False False restore_from_snapshot True safety False False Outputs Name Description db_host db_name db_password db_user global_database_id","title":"aws_postgres"},{"location":"references/modules/aws_postgres/#what-it-does","text":"Provisions an Aurora Postgres cluster in private subnets with encryption. Supports multi-AZ, backups, retention, and public accessibility toggle. Exposes writer/reader endpoints and security/subnet group metadata.","title":"What it does"},{"location":"references/modules/aws_postgres/#fields","text":"Name Description Default Required backup_retention_days How many days to keep the backup retention True create_global_database True database_name True engine_version 11.9 False existing_global_database_id True extra_security_groups_ids True instance_class db.t3.medium False multi_az False False restore_from_snapshot True safety False False","title":"Fields"},{"location":"references/modules/aws_postgres/#outputs","text":"Name Description db_host db_name db_password db_user global_database_id","title":"Outputs"},{"location":"references/modules/aws_redis/","text":"Provisions ElastiCache Redis with subnet group, encryption in-transit/at-rest, and parameter options. What it does Deploys ElastiCache Redis cluster/subnet group with in-transit/at-rest encryption. Configurable engine version, node class, cluster size, and parameter family. Outputs cache endpoints and security group details. Fields Name Description Default Required node_type cache.m4.large False redis_version 6.x False snapshot_retention_limit Days for which the Snapshot should be retained. 0 False snapshot_window When should the Snapshot for redis cache be done. UTC Time. Snapshot Retention Limit should be set to more than 0. 04:00-05:00 False Outputs Name Description cache_auth_token cache_host Redis host.","title":"aws_redis"},{"location":"references/modules/aws_redis/#what-it-does","text":"Deploys ElastiCache Redis cluster/subnet group with in-transit/at-rest encryption. Configurable engine version, node class, cluster size, and parameter family. Outputs cache endpoints and security group details.","title":"What it does"},{"location":"references/modules/aws_redis/#fields","text":"Name Description Default Required node_type cache.m4.large False redis_version 6.x False snapshot_retention_limit Days for which the Snapshot should be retained. 0 False snapshot_window When should the Snapshot for redis cache be done. UTC Time. Snapshot Retention Limit should be set to more than 0. 04:00-05:00 False","title":"Fields"},{"location":"references/modules/aws_redis/#outputs","text":"Name Description cache_auth_token cache_host Redis host.","title":"Outputs"},{"location":"references/modules/aws_s3/","text":"Creates an S3 bucket with encryption, versioning, lifecycle/replication options, and optional bucket policies. What it does Creates an encrypted S3 bucket (AES-256) with block-public-access by default. Supports custom bucket policy, CORS rules, and optional same-region replication. Optionally uploads static files with content-type detection and creates an OAI for CloudFront reads when needed. Can emit access logs to the provided log bucket. Fields Name Description Default Required block_public True False bucket_name True bucket_policy False cors_rule CORS configuration for the bucket. False files False s3_log_bucket_name False same_region_replication False False Outputs Name Description bucket_arn Bucket ARN. bucket_id Bucket name/ID. cloudfront_read_path Origin access identity path (if created).","title":"aws_s3"},{"location":"references/modules/aws_s3/#what-it-does","text":"Creates an encrypted S3 bucket (AES-256) with block-public-access by default. Supports custom bucket policy, CORS rules, and optional same-region replication. Optionally uploads static files with content-type detection and creates an OAI for CloudFront reads when needed. Can emit access logs to the provided log bucket.","title":"What it does"},{"location":"references/modules/aws_s3/#fields","text":"Name Description Default Required block_public True False bucket_name True bucket_policy False cors_rule CORS configuration for the bucket. False files False s3_log_bucket_name False same_region_replication False False","title":"Fields"},{"location":"references/modules/aws_s3/#outputs","text":"Name Description bucket_arn Bucket ARN. bucket_id Bucket name/ID. cloudfront_read_path Origin access identity path (if created).","title":"Outputs"},{"location":"references/modules/aws_ses/","text":"Configures SES domain/identities with DNS verification records and optional inbound/notification settings. What it does Verifies a domain in SES and configures MAIL FROM. Creates IAM policy for sending and exposes DKIM tokens and identity ARN. Fields Name Description Default Required domain True mail_from_prefix mail False zone_id True Outputs Name Description identity_arn SES identity ARN. sender_policy_arn IAM policy ARN permitting SES send.","title":"aws_ses"},{"location":"references/modules/aws_ses/#what-it-does","text":"Verifies a domain in SES and configures MAIL FROM. Creates IAM policy for sending and exposes DKIM tokens and identity ARN.","title":"What it does"},{"location":"references/modules/aws_ses/#fields","text":"Name Description Default Required domain True mail_from_prefix mail False zone_id True","title":"Fields"},{"location":"references/modules/aws_ses/#outputs","text":"Name Description identity_arn SES identity ARN. sender_policy_arn IAM policy ARN permitting SES send.","title":"Outputs"},{"location":"references/modules/aws_sns/","text":"Creates an SNS topic with encryption, delivery policies, and optional subscriptions. What it does Creates an SNS topic (standard or FIFO) with a dedicated KMS CMK. Applies a default topic policy for account root and subscribes provided SQS endpoints. Supports content-based deduplication for FIFO topics and custom delivery policy. Fields Name Description Default Required content_based_deduplication Enable content-based deduplication for FIFO topics. False False fifo Create a FIFO topic (adds .fifo suffix). False False sqs_subscribers List of SQS queue ARNs to subscribe. [] False Outputs Name Description kms_arn KMS key ARN for the topic. topic_arn SNS topic ARN.","title":"aws_sns"},{"location":"references/modules/aws_sns/#what-it-does","text":"Creates an SNS topic (standard or FIFO) with a dedicated KMS CMK. Applies a default topic policy for account root and subscribes provided SQS endpoints. Supports content-based deduplication for FIFO topics and custom delivery policy.","title":"What it does"},{"location":"references/modules/aws_sns/#fields","text":"Name Description Default Required content_based_deduplication Enable content-based deduplication for FIFO topics. False False fifo Create a FIFO topic (adds .fifo suffix). False False sqs_subscribers List of SQS queue ARNs to subscribe. [] False","title":"Fields"},{"location":"references/modules/aws_sns/#outputs","text":"Name Description kms_arn KMS key ARN for the topic. topic_arn SNS topic ARN.","title":"Outputs"},{"location":"references/modules/aws_sqs/","text":"Creates an SQS queue with encryption, visibility timeout, redrive policy, and optional DLQ linkage. What it does Creates an SQS queue (standard or FIFO) with a dedicated KMS CMK. Configures default queue policy allowing account root, SNS, and EventBridge producers. Supports content-based deduplication, delivery delays, retention, and long polling. Outputs KMS ARN for wiring IRSA/IAM consumers. Fields Name Description Default Required content_based_deduplication Enable content-based deduplication for FIFO queues. False False delay_seconds 0 False fifo Create a FIFO queue (adds .fifo suffix). False False message_retention_seconds 345600 False receive_wait_time_seconds 0 False Outputs Name Description kms_arn KMS key ARN for the queue. queue_arn SQS queue ARN. queue_id SQS queue URL. queue_name SQS queue name.","title":"aws_sqs"},{"location":"references/modules/aws_sqs/#what-it-does","text":"Creates an SQS queue (standard or FIFO) with a dedicated KMS CMK. Configures default queue policy allowing account root, SNS, and EventBridge producers. Supports content-based deduplication, delivery delays, retention, and long polling. Outputs KMS ARN for wiring IRSA/IAM consumers.","title":"What it does"},{"location":"references/modules/aws_sqs/#fields","text":"Name Description Default Required content_based_deduplication Enable content-based deduplication for FIFO queues. False False delay_seconds 0 False fifo Create a FIFO queue (adds .fifo suffix). False False message_retention_seconds 345600 False receive_wait_time_seconds 0 False","title":"Fields"},{"location":"references/modules/aws_sqs/#outputs","text":"Name Description kms_arn KMS key ARN for the queue. queue_arn SQS queue ARN. queue_id SQS queue URL. queue_name SQS queue name.","title":"Outputs"},{"location":"security/aws/","text":"Architecture overview for AWS deployments of pltf. Description Single-region deployments with networking across three AZs by default (public + private subnets). Public subnets are used for public load balancers; EC2/Databases stay in private subnets (NAT for egress). EKS cluster spans private subnets with managed node groups. Cluster version is configurable ( aws_eks.k8s_version ) and patched by AWS. Public endpoint by default (VPN/private endpoints can be added later). Secrets are encrypted via KMS. Datastores: modules for Postgres (Aurora), Redis (ElastiCache), DocumentDB. Multi-AZ supported; 5-day backup retention for Postgres/DocumentDB. Credentials are generated and passed securely to services. S3: buckets are private by default, encrypted at rest (AES-256); can be made public via inputs. SQS: queues created with dedicated KMS keys for encryption at rest. SNS: topics created with dedicated KMS keys for encryption at rest. IAM: IAM role/user modules with links auto-generate least-privilege policies (S3, SQS, SNS, SES, etc.) and IRSA trusts for Kubernetes services. DNS/SSL: Route53 hosted zone and ACM certificates; validation via Route53; records created to point to the load balancer. Security Overview End-to-end TLS when using ingress + service mesh (Linkerd optional) and delegated domains. Databases and EC2s in private subnets; only NAT egress. Databases (Postgres/Redis/DocumentDB) encrypted at rest with KMS; connections use SSL. S3 buckets encrypted at rest (AES-256); private by default. SQS/SNS encrypted at rest with per-resource KMS keys. Networking gated by security groups (EKS-managed + module-specific SGs) with minimal port exposure. EKS nodes created with scoped IAM policies; cluster storage (Secrets) encrypted via KMS. K8s service accounts mapped to IAM roles via OIDC (IRSA); no long-lived credentials. No long-lived IAM credentials are created by default; ECR images remain private. 5-day backup retention for Postgres/DocumentDB. Public EKS endpoint by default for simplicity; private/VPN options can be layered later.","title":"AWS Architecture"},{"location":"security/aws/#description","text":"Single-region deployments with networking across three AZs by default (public + private subnets). Public subnets are used for public load balancers; EC2/Databases stay in private subnets (NAT for egress). EKS cluster spans private subnets with managed node groups. Cluster version is configurable ( aws_eks.k8s_version ) and patched by AWS. Public endpoint by default (VPN/private endpoints can be added later). Secrets are encrypted via KMS. Datastores: modules for Postgres (Aurora), Redis (ElastiCache), DocumentDB. Multi-AZ supported; 5-day backup retention for Postgres/DocumentDB. Credentials are generated and passed securely to services. S3: buckets are private by default, encrypted at rest (AES-256); can be made public via inputs. SQS: queues created with dedicated KMS keys for encryption at rest. SNS: topics created with dedicated KMS keys for encryption at rest. IAM: IAM role/user modules with links auto-generate least-privilege policies (S3, SQS, SNS, SES, etc.) and IRSA trusts for Kubernetes services. DNS/SSL: Route53 hosted zone and ACM certificates; validation via Route53; records created to point to the load balancer.","title":"Description"},{"location":"security/aws/#security-overview","text":"End-to-end TLS when using ingress + service mesh (Linkerd optional) and delegated domains. Databases and EC2s in private subnets; only NAT egress. Databases (Postgres/Redis/DocumentDB) encrypted at rest with KMS; connections use SSL. S3 buckets encrypted at rest (AES-256); private by default. SQS/SNS encrypted at rest with per-resource KMS keys. Networking gated by security groups (EKS-managed + module-specific SGs) with minimal port exposure. EKS nodes created with scoped IAM policies; cluster storage (Secrets) encrypted via KMS. K8s service accounts mapped to IAM roles via OIDC (IRSA); no long-lived credentials. No long-lived IAM credentials are created by default; ECR images remain private. 5-day backup retention for Postgres/DocumentDB. Public EKS endpoint by default for simplicity; private/VPN options can be layered later.","title":"Security Overview"},{"location":"security/azure/","text":"Placeholder. Cover identity (AAD/SP), backend hardening, and network segmentation.","title":"Azure"},{"location":"security/compliance/","text":"SOC 2 and PCI considerations for infrastructure deployed by pltf. Overview pltf aims to make SOC 2 and PCI alignment the default for cloud resources it provisions. Compliance is broader than infrastructure; this covers only the cloud layer. Engage a compliance partner for full org-level readiness. Methodology We scan representative environments with Fugue/Regula for SOC2/PCI controls before releases. Findings are fixed when possible; otherwise documented below. Backward-incompatible changes are avoided; new defaults apply to newly created resources. AWS AWS infrastructure can meet SOC2/PCI with the following settings: - S3 buckets: deny non-SSL traffic; enable same_region_replication for backups. - Postgres (Aurora): enable multi_az . Example: modules : - name : db type : aws_postgres multi_az : true - name : s3 type : aws_s3 same_region_replication : true bucket_policy : Version : \"2012-10-17\" Statement : - Sid : denyInsecureTransport Effect : Deny Principal : \"*\" Action : \"s3:*\" Resource : - \"arn:aws:s3:::${parent_name}-${layer_name}/*\" - \"arn:aws:s3:::${parent_name}-${layer_name}\" Condition : Bool : aws:SecureTransport : \"false\" Notes auditors may raise: - Terraform lock DynamoDB table is unencrypted (no customer data, only hashes). - Terraform state bucket logging is not enabled by default (bootstrap ordering). You may manually add logging to the log bucket. - The log bucket does not log itself. GCP Current gaps to full SOC2/PCI: - GKE nodegroup VMs cannot disable block-project-ssh-keys easily. - GKE node disks via KMS key encryption are still limited (beta in TF); will adopt when GA. - Defaults without uniform bucket-level access (GCS state bucket, GCR-backed bucket) to avoid tedious per-user grants; can be manually enabled if desired. Azure Azure can meet SOC2/PCI with an extra user step: - Enable flow logs for the agent pool security group. We continue to monitor provider capabilities and will tighten defaults as features mature.","title":"Compliance"},{"location":"security/compliance/#overview","text":"pltf aims to make SOC 2 and PCI alignment the default for cloud resources it provisions. Compliance is broader than infrastructure; this covers only the cloud layer. Engage a compliance partner for full org-level readiness.","title":"Overview"},{"location":"security/compliance/#methodology","text":"We scan representative environments with Fugue/Regula for SOC2/PCI controls before releases. Findings are fixed when possible; otherwise documented below. Backward-incompatible changes are avoided; new defaults apply to newly created resources.","title":"Methodology"},{"location":"security/compliance/#aws","text":"AWS infrastructure can meet SOC2/PCI with the following settings: - S3 buckets: deny non-SSL traffic; enable same_region_replication for backups. - Postgres (Aurora): enable multi_az . Example: modules : - name : db type : aws_postgres multi_az : true - name : s3 type : aws_s3 same_region_replication : true bucket_policy : Version : \"2012-10-17\" Statement : - Sid : denyInsecureTransport Effect : Deny Principal : \"*\" Action : \"s3:*\" Resource : - \"arn:aws:s3:::${parent_name}-${layer_name}/*\" - \"arn:aws:s3:::${parent_name}-${layer_name}\" Condition : Bool : aws:SecureTransport : \"false\" Notes auditors may raise: - Terraform lock DynamoDB table is unencrypted (no customer data, only hashes). - Terraform state bucket logging is not enabled by default (bootstrap ordering). You may manually add logging to the log bucket. - The log bucket does not log itself.","title":"AWS"},{"location":"security/compliance/#gcp","text":"Current gaps to full SOC2/PCI: - GKE nodegroup VMs cannot disable block-project-ssh-keys easily. - GKE node disks via KMS key encryption are still limited (beta in TF); will adopt when GA. - Defaults without uniform bucket-level access (GCS state bucket, GCR-backed bucket) to avoid tedious per-user grants; can be manually enabled if desired.","title":"GCP"},{"location":"security/compliance/#azure","text":"Azure can meet SOC2/PCI with an extra user step: - Enable flow logs for the agent pool security group. We continue to monitor provider capabilities and will tighten defaults as features mature.","title":"Azure"},{"location":"security/gcp/","text":"Placeholder. Discuss IAM, service accounts, backend security, and network controls.","title":"Gcp"},{"location":"security/kubernetes/","text":"Architecture overview for Kubernetes clusters deployed by pltf. Description pltf divides the cluster into namespaces for third-party integrations and for your services. Third-party components are deployed via Helm charts (v3) into their own namespaces; your services are deployed into namespaces derived from the service/layer name. Third-party integrations (common set) Linkerd (service mesh) \u2014 mTLS, traffic control, golden metrics; chosen for simplicity and security. Metrics Server \u2014 HPA metrics (built-in on GKE/Azure; installed on EKS). Cluster Autoscaler \u2014 scales nodes (built-in on GKE/Azure; installed on EKS). Ingress NGINX \u2014 ingress controller routing LB traffic into the cluster. External DNS \u2014 manages DNS records for LBs (not needed on GKE/Azure by default). Datadog (optional) \u2014 metrics/logs/APM via the Datadog K8s integration module. Services (pltf modules) Each service ( aws_k8s_service / gcp_k8s_service ) creates: - Namespace named from the service (layer) name. - Deployment + pods, Service, optional Ingress. - Horizontal Pod Autoscaler (CPU/memory driven). - Service Account wired to cloud IAM via IRSA/Workload Identity; least privilege via links. - ConfigMap/Secrets for app config and credentials (secrets encrypted at rest by the cloud). - Internal DNS of the form <module_name>.<layer_name> for service-to-service calls. Security Overview Linkerd mTLS secures cross-service traffic. Official/Bitnami Helm charts, version-locked; IAM roles scoped to least privilege. Service accounts per service; no extra cluster roles granted by default. IRSA/Workload Identity/OIDC for cloud access; no long-lived credentials in pods. Secrets stored in K8s are encrypted at rest; cloud KMS used by the control plane. plft does not modify aws-auth beyond optional admin_arns configuration. Helm v3 used for all chart deployments.","title":"Kubernetes Architecture"},{"location":"security/kubernetes/#description","text":"pltf divides the cluster into namespaces for third-party integrations and for your services. Third-party components are deployed via Helm charts (v3) into their own namespaces; your services are deployed into namespaces derived from the service/layer name.","title":"Description"},{"location":"security/kubernetes/#third-party-integrations-common-set","text":"Linkerd (service mesh) \u2014 mTLS, traffic control, golden metrics; chosen for simplicity and security. Metrics Server \u2014 HPA metrics (built-in on GKE/Azure; installed on EKS). Cluster Autoscaler \u2014 scales nodes (built-in on GKE/Azure; installed on EKS). Ingress NGINX \u2014 ingress controller routing LB traffic into the cluster. External DNS \u2014 manages DNS records for LBs (not needed on GKE/Azure by default). Datadog (optional) \u2014 metrics/logs/APM via the Datadog K8s integration module.","title":"Third-party integrations (common set)"},{"location":"security/kubernetes/#services-pltf-modules","text":"Each service ( aws_k8s_service / gcp_k8s_service ) creates: - Namespace named from the service (layer) name. - Deployment + pods, Service, optional Ingress. - Horizontal Pod Autoscaler (CPU/memory driven). - Service Account wired to cloud IAM via IRSA/Workload Identity; least privilege via links. - ConfigMap/Secrets for app config and credentials (secrets encrypted at rest by the cloud). - Internal DNS of the form <module_name>.<layer_name> for service-to-service calls.","title":"Services (pltf modules)"},{"location":"security/kubernetes/#security-overview","text":"Linkerd mTLS secures cross-service traffic. Official/Bitnami Helm charts, version-locked; IAM roles scoped to least privilege. Service accounts per service; no extra cluster roles granted by default. IRSA/Workload Identity/OIDC for cloud access; no long-lived credentials in pods. Secrets stored in K8s are encrypted at rest; cloud KMS used by the control plane. plft does not modify aws-auth beyond optional admin_arns configuration. Helm v3 used for all chart deployments.","title":"Security Overview"}]}